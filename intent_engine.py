# intent_engine.py

import json
import unicodedata
from typing import List, Dict, Any

import requests

from config import (
    client,
    HOTLINE,
    FANPAGE_URL,
    ZALO_OA_URL,
    WEBSITE_URL,
    LOG_WEBHOOK_URL,
)
from health_engine import (
    extract_tags_from_text,
    select_combos_for_tags,
    search_products_by_tags,
)
from db_utils import get_last_user_message_from_history

# =====================================================================
#   TEXT & MODE UTILS
# =====================================================================

def strip_accents(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if not unicodedata.combining(ch))
    return text


def looks_like_repeat_request(text: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u ki·ªÉu: 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n / v·ª´a n√£y'.
    """
    if not text:
        return False
    t = strip_accents(text)
    t = " ".join(t.split())

    patterns = [
        "tra loi lai cau hoi",
        "tra loi lai cau tren",
        "tra loi lai cau vua nay",
        "tra loi lai cau truoc",
        "hoi lai cau hoi truoc",
        "hoi lai cau truoc",
    ]
    return any(p in t for p in patterns)


def looks_like_followup(text: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u follow-up d·ª±a tr√™n c√¢u tr·∫£ l·ªùi tr∆∞·ªõc:
    'combo tr√™n u·ªëng bao l√¢u', 's·∫£n ph·∫©m ƒë√≥ gi√° bao nhi√™u', ...
    """
    if not text:
        return False
    t = strip_accents(text)
    t = " ".join(t.split())

    # Nh·∫Øc 'combo / s·∫£n ph·∫©m / g√≥i' + 'tr√™n / ƒë√≥ / v·ª´a n√£y / tr∆∞·ªõc'
    core_phrases = [
        "combo tren",
        "combo truoc",
        "combo vua nay",
        "combo do",
        "san pham tren",
        "san pham truoc",
        "san pham vua nay",
        "san pham do",
        "goi tren",
        "goi truoc",
        "goi vua nay",
        "goi do",
    ]
    if any(p in t for p in core_phrases):
        return True

    # C√¢u h·ªèi v·ªÅ th·ªùi gian u·ªëng / li·ªÅu / gi√° m√† th∆∞·ªùng l√† follow-up
    if "bao lau" in t and ("uong" in t or "dung" in t):
        return True
    if "gia bao nhieu" in t or "gia the nao" in t:
        return True
    if "moi lan uong" in t or "ngay uong" in t or "cach uong" in t or "cach dung" in t:
        return True

    return False


def is_meta_for_customer(text_norm: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u ki·ªÉu: anh/ch·ªã ƒëang h·ªèi gi√πm kh√°ch.
    """
    meta_kw = [
        "anh hoi cho khach",
        "em hoi cho khach",
        "hoi cho khach",
        "hoi giup khach",
        "hoi giup ban",
        "tu van vien",
        "tvv",
    ]
    return any(k in text_norm for k in meta_kw)


def is_duration_followup(text_norm: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u h·ªèi v·ªÅ th·ªùi gian d√πng / li·ªáu tr√¨nh (c√≥ th·ªÉ kh√¥ng nh·∫Øc 'combo tr√™n').
    """
    duration_kw = [
        "bao lau",
        "bao l√¢u",
        "may ngay",
        "m·∫•y ng√†y",
        "may thang",
        "m·∫•y th√°ng",
        "dung trong bao",
        "u·ªëng trong bao",
        "lieu trinh",
        "li·ªáu tr√¨nh",
        "thoi gian dung",
        "th·ªùi gian d√πng",
    ]
    return any(strip_accents(k) in text_norm for k in duration_kw)


def detect_mode(user_message: str) -> str:
    """ƒêo√°n xem user ƒëang h·ªèi v·ªÅ combo / s·∫£n ph·∫©m / mua h√†ng / k√™nh / kinh doanh."""
    text_norm = strip_accents(user_message)

    # H·ªèi kinh doanh, ch√≠nh s√°ch, hoa h·ªìng
    business_keywords = [
        "chinh sach",
        "hoa hong",
        "tuyen dung",
        "len cap",
        "leader",
        "doanh so",
        "muc tieu thang",
    ]
    if any(k in text_norm for k in business_keywords):
        return "business"

    # H·ªèi mua h√†ng / thanh to√°n
    buy_keywords = [
        "mua",
        "dat hang",
        "thanh toan",
        "ship",
        "giao hang",
        "dat mua",
    ]
    if any(k in text_norm for k in buy_keywords):
        return "buy"

    # H·ªèi k√™nh, fanpage, zalo
    channel_keywords = [
        "fanpage",
        "zalo",
        "kenh",
        "website",
        "trang web",
    ]
    if any(k in text_norm for k in channel_keywords):
        return "channel"

    # Nh·∫Øc ƒë·∫øn combo / s·∫£n ph·∫©m
    if "combo" in text_norm:
        return "combo"
    if "san pham" in text_norm or "s·∫£n ph·∫©m" in user_message.lower():
        return "product"

    return "auto"


# =====================================================================
#   OPENAI RESPONSES & INTENT CLASSIFIER
# =====================================================================

def call_openai_responses(prompt_text: str) -> str:
    """G·ªçi Responses API gi·ªëng style d·ª± √°n c≈© c·ªßa anh."""
    try:
        res = client.responses.create(
            model="gpt-4.1-mini",
            input=prompt_text,
        )
        reply_text = getattr(res, "output_text", "") or ""
        reply_text = reply_text.strip()
        if not reply_text:
            reply_text = "Hi·ªán t·∫°i em kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ h·ªá th·ªëng OpenAI."
        return reply_text
    except Exception as e:
        print("‚ùå ERROR OpenAI Responses:", e)
        return (
            "Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng AI ƒëang g·∫∑p l·ªói, anh/ch·ªã vui l√≤ng th·ª≠ l·∫°i sau "
            "ho·∫∑c li√™n h·ªá hotline ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp."
        )


def safe_parse_json(text: str, default=None):
    """C·ªë g·∫Øng b√≥c JSON t·ª´ c√¢u tr·∫£ l·ªùi c·ªßa model."""
    if default is None:
        default = {}
    if not text:
        return default
    try:
        return json.loads(text)
    except Exception:
        # Th·ª≠ b√≥c t·ª´ { ... }
        try:
            start = text.find("{")
            end = text.rfind("}")
            if start != -1 and end != -1 and end > start:
                return json.loads(text[start : end + 1])
        except Exception:
            return default
    return default


def ai_classify_intent(
    user_message: str, history_messages: List[Dict[str, Any]] | None = None
) -> dict:
    """
    Ph√¢n lo·∫°i √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng:
    - greeting: ch√†o h·ªèi
    - smalltalk: n√≥i chuy·ªán linh tinh, h·ªèi thƒÉm, c√¢u ƒë·ªùi th∆∞·ªùng
    - health_question: h·ªèi v·ªÅ v·∫•n ƒë·ªÅ s·ª©c kh·ªèe chung (ch∆∞a r√µ combo/s·∫£n ph·∫©m)
    - product_question: h·ªèi v·ªÅ 1 s·∫£n ph·∫©m c·ª• th·ªÉ
    - combo_question: h·ªèi g·ª£i √Ω combo
    - business_policy: ch√≠nh s√°ch / hoa h·ªìng / tuy·ªÉn d·ª•ng
    - buy_payment: c√°ch mua h√†ng, thanh to√°n, giao h√†ng
    - channel_info: h·ªèi link fanpage, zalo, website, k√™nh li√™n h·ªá
    - other: kh√¥ng r√µ / ch·ªß ƒë·ªÅ kh√°c
    """
    history_messages = history_messages or []
    # Gh√©p l·ªãch s·ª≠ th√†nh text
    history_text_lines = []
    for m in history_messages[-6:]:  # l·∫•y t·ªëi ƒëa 6 c√¢u g·∫ßn nh·∫•t
        role = m.get("role", "user")
        content = (m.get("content") or "").replace("\n", " ").strip()
        if not content:
            continue
        prefix = "KH√ÅCH" if role == "user" else "BOT"
        history_text_lines.append(f"{prefix}: {content}")
    history_text = "\n".join(history_text_lines)

    prompt = f"""
B·∫°n l√† module PH√ÇN LO·∫†I √ù ƒê·ªäNH cho chatbot t∆∞ v·∫•n s·ª©c kh·ªèe & s·∫£n ph·∫©m Greenway / Welllab.

Nhi·ªám v·ª•:
- Ch·ªâ ph√¢n lo·∫°i √Ω ƒë·ªãnh, KH√îNG t·ª± t∆∞ v·∫•n s·ª©c kh·ªèe.
- D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i (n·∫øu c√≥) v√† c√¢u m·ªõi nh·∫•t c·ªßa ng∆∞·ªùi d√πng.

C√°c lo·∫°i intent h·ª£p l·ªá:
- "greeting"       : ch√†o h·ªèi, h·ªèi thƒÉm ki·ªÉu "ch√†o em", "hello", "d·∫°o n√†y sao r·ªìi"...
- "smalltalk"      : n√≥i chuy·ªán ƒë·ªùi th∆∞·ªùng, h·ªèi linh tinh, ƒë√πa vui, kh√¥ng y√™u c·∫ßu t∆∞ v·∫•n s·∫£n ph·∫©m/ch√≠nh s√°ch.
- "health_question": h·ªèi v·ªÅ tri·ªáu ch·ª©ng, t√¨nh tr·∫°ng s·ª©c kh·ªèe chung (c√≥ ho·∫∑c kh√¥ng nh·∫Øc combo/s·∫£n ph·∫©m).
- "product_question": h·ªèi v·ªÅ M·ªòT s·∫£n ph·∫©m c·ª• th·ªÉ, t√™n, c√°ch d√πng, t√°c d·ª•ng, gi√°, link...
- "combo_question" : h·ªèi g·ª£i √Ω combo / b·ªô s·∫£n ph·∫©m cho v·∫•n ƒë·ªÅ s·ª©c kh·ªèe.
- "business_policy": h·ªèi v·ªÅ ch√≠nh s√°ch, hoa h·ªìng, tuy·ªÉn d·ª•ng, thƒÉng c·∫•p, KPI, doanh s·ªë...
- "buy_payment"    : h·ªèi v·ªÅ c√°ch mua h√†ng, giao h√†ng, thanh to√°n.
- "channel_info"   : h·ªèi xin link fanpage, Zalo OA, website, k√™nh li√™n h·ªá.
- "other"          : m·ªçi tr∆∞·ªùng h·ª£p kh√°c kh√¥ng n·∫±m trong c√°c nh√≥m tr√™n.

H√£y tr·∫£ v·ªÅ JSON **duy nh·∫•t**, kh√¥ng gi·∫£i th√≠ch th√™m, d·∫°ng:

{{
  "intent": "greeting | smalltalk | health_question | product_question | combo_question | business_policy | buy_payment | channel_info | other",
  "reason": "gi·∫£i th√≠ch r·∫•t ng·∫Øn, ti·∫øng Vi·ªát"
}}

----- L·ªäCH S·ª¨ H·ªòI THO·∫†I (n·∫øu c√≥) -----
{history_text}

----- C√ÇU M·ªöI NH·∫§T C·ª¶A NG∆Ø·ªúI D√ôNG -----
"{user_message}"
"""

    raw = call_openai_responses(prompt)
    data = safe_parse_json(raw, default={"intent": "other", "reason": ""})
    intent = data.get("intent") or "other"
    data["intent"] = intent
    return data


# =====================================================================
#   LLM ANSWERS (COMBO / PRODUCT / HISTORY)
# =====================================================================

def llm_answer_for_combos(
    user_question: str,
    requested_tags: List[str],
    combos: List[dict],
    covered_tags: List[str],
    extra_instruction: str = "",
) -> str:
    if not combos:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y combo ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n t∆∞ v·∫•n chi ti·∫øt h∆°n ·∫°."
        )

    combos_json = json.dumps(combos, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu combo v√† s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

D∆∞·ªõi ƒë√¢y l√† c√¢u h·ªèi v√† d·ªØ li·ªáu:

- C√¢u h·ªèi c·ªßa kh√°ch / t∆∞ v·∫•n vi√™n: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe h·ªá th·ªëng tr√≠ch xu·∫•t ƒë∆∞·ª£c: {tags_text}

D·ªØ li·ªáu c√°c combo ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{combos_json}

H∆∞·ªõng d·∫´n b·ªï sung t·ª´ h·ªá th·ªëng (n·∫øu c√≥, c√≥ th·ªÉ ƒë·ªÉ tr·ªëng):
{extra_instruction}

Y√äU C·∫¶U TR·∫¢ L·ªúI (b·∫±ng ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu, r√µ r√†ng):

1. M·ªü ƒë·∫ßu 1‚Äì3 c√¢u: t√≥m t·∫Øt c√°c v·∫•n ƒë·ªÅ/nhu c·∫ßu ch√≠nh v√† ƒë·ªãnh h∆∞·ªõng x·ª≠ l√Ω (theo combo) cho kh√°ch.
2. V·ªõi t·ª´ng combo:
   - N√™u r√µ combo n√†y h·ªó tr·ª£ nh·ªØng v·∫•n ƒë·ªÅ n√†o trong c√°c v·∫•n ƒë·ªÅ kh√°ch ƒëang g·∫∑p.
   - Li·ªát k√™ t·ª´ng s·∫£n ph·∫©m trong combo:
     + T√™n s·∫£n ph·∫©m
     + L·ª£i √≠ch ch√≠nh / t√°c d·ª•ng h·ªó tr·ª£
     + Th·ªùi gian d√πng g·ª£i √Ω (n·∫øu c√≥ trong d·ªØ li·ªáu)
     + C√°ch d√πng t√≥m t·∫Øt (d·ª±a tr√™n dose_text/usage_text n·∫øu c√≥)
     + Gi√° (price_text)
     + Link s·∫£n ph·∫©m (product_url)
3. N·∫øu v·∫•n ƒë·ªÅ c√≥ v·∫ª n·∫∑ng/nh·∫°y c·∫£m (ung th∆∞, tim m·∫°ch n·∫∑ng, suy th·∫≠n, v.v.) h√£y khuy·∫øn ngh·ªã kh√°ch n√™n thƒÉm kh√°m v√† t√°i kh√°m ƒë·ªãnh k·ª≥.
4. Cu·ªëi c√¢u tr·∫£ l·ªùi, lu√¥n nh·∫Øc: "S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.".
5. Vi·∫øt gi·ªçng ƒëi·ªáu g·∫ßn g≈©i, l·ªãch s·ª±, h∆∞·ªõng d·∫´n nh∆∞ ƒëang n√≥i chuy·ªán v·ªõi t∆∞ v·∫•n vi√™n/kh√°ch h√†ng th·∫≠t.
"""
    return call_openai_responses(prompt)


def llm_answer_for_products(
    user_question: str,
    requested_tags: List[str],
    products: List[dict],
    extra_instruction: str = "",
) -> str:
    if not products:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n r√µ h∆°n ·∫°."
        )

    products_json = json.dumps(products, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

- C√¢u h·ªèi: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe: {tags_text}

D·ªØ li·ªáu c√°c s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{products_json}

H∆∞·ªõng d·∫´n b·ªï sung t·ª´ h·ªá th·ªëng (n·∫øu c√≥, c√≥ th·ªÉ ƒë·ªÉ tr·ªëng):
{extra_instruction}

Y√äU C·∫¶U TR·∫¢ L·ªúI:

1. M·ªü ƒë·∫ßu 1‚Äì2 c√¢u: gi·ªõi thi·ªáu ƒë√¢y l√† c√°c s·∫£n ph·∫©m h·ªó tr·ª£ ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ m√† kh√°ch ƒëang g·∫∑p.
2. V·ªõi t·ª´ng s·∫£n ph·∫©m:
   - T√™n s·∫£n ph·∫©m
   - V·∫•n ƒë·ªÅ ch√≠nh m√† s·∫£n ph·∫©m h·ªó tr·ª£ (d·ª±a tr√™n group/health_tags)
   - L·ª£i √≠ch ch√≠nh (d·ª±a tr√™n benefits_text ho·∫∑c m√¥ t·∫£)
   - C√°ch d√πng t√≥m t·∫Øt (usage_text ho·∫∑c dose_text n·∫øu c√≥)
   - Gi√° (price_text)
   - Link s·∫£n ph·∫©m (product_url)
3. Cu·ªëi c√πng nh·∫Øc: "S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh."
4. Vi·∫øt ng·∫Øn g·ªçn, r√µ r√†ng, d·ªÖ d√πng cho t∆∞ v·∫•n vi√™n khi ch√°t v·ªõi kh√°ch.
"""
    return call_openai_responses(prompt)


def llm_answer_with_history(latest_question: str, history: List[Dict[str, Any]]) -> str:
    """
    D√πng khi c√¢u h·ªèi l√† follow-up: t·∫≠n d·ª•ng transcript h·ªôi tho·∫°i g·∫ßn ƒë√¢y.
    """
    if not history:
        # fallback cho ch·∫Øc
        return call_openai_responses(
            f"Kh√°ch h·ªèi: {latest_question}\nH√£y t∆∞ v·∫•n nh∆∞ tr·ª£ l√Ω Greenway/Welllab."
        )

    lines = []
    # L·∫•y kho·∫£ng 10 message g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh prompt qu√° d√†i
    for msg in history[-10:]:
        role = msg.get("role")
        prefix = "Kh√°ch" if role == "user" else "Tr·ª£ l√Ω"
        content = msg.get("content", "")
        lines.append(f"{prefix}: {content}")
    convo = "\n".join(lines)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n s·ª©c kh·ªèe & s·∫£n ph·∫©m cho Greenway/Welllab.

D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n h·ªôi tho·∫°i g·∫ßn ƒë√¢y gi·ªØa kh√°ch v√† tr·ª£ l√Ω (b·∫°n):

{convo}

C√¢u h·ªèi m·ªõi nh·∫•t c·ªßa kh√°ch l√†: "{latest_question}"

NHI·ªÜM V·ª§:

1. Hi·ªÉu 'combo tr√™n', 'combo ƒë√≥', 's·∫£n ph·∫©m tr√™n', 's·∫£n ph·∫©m ƒë√≥', 'g√≥i tr√™n'...
   l√† ƒëang n√≥i v·ªÅ combo/s·∫£n ph·∫©m m√† b·∫°n v·ª´a t∆∞ v·∫•n tr∆∞·ªõc ƒë√≥ trong ƒëo·∫°n h·ªôi tho·∫°i.
2. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, d·ª±a tr√™n th√¥ng tin ƒë√£ ƒë∆∞·ª£c t∆∞ v·∫•n ·ªü tr√™n
   (li·ªÅu d√πng, th·ªùi gian u·ªëng, s·ªë vi√™n m·ªói ng√†y, gi√°, c√°ch d√πng...).
3. N·∫øu trong ƒëo·∫°n h·ªôi tho·∫°i ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√≥i r√µ:
   'Trong ph·∫ßn t∆∞ v·∫•n ph√≠a tr√™n em ch∆∞a ghi r√µ ph·∫ßn n√†y, anh/ch·ªã cho em xin l·∫°i c√¢u h·ªèi ƒë·∫ßy ƒë·ªß h∆°n...'
4. Cu·ªëi c√πng v·∫´n nh·∫Øc: S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh (n·∫øu c√¢u tr·∫£ l·ªùi li√™n quan ƒë·∫øn s·∫£n ph·∫©m).

B·∫Øt ƒë·∫ßu tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, gi·ªçng t∆∞ v·∫•n vi√™n th√¢n thi·ªán, chuy√™n nghi·ªáp.
"""
    return call_openai_responses(prompt)


# =====================================================================
#   HANDLER M·∫∂C ƒê·ªäNH & LOG
# =====================================================================

def handle_buy_and_payment_info() -> str:
    return (
        "ƒê·ªÉ mua h√†ng, anh/ch·ªã c√≥ th·ªÉ ch·ªçn m·ªôt trong c√°c c√°ch sau:\n\n"
        "1Ô∏è‚É£ ƒê·∫∑t h√†ng tr·ª±c ti·∫øp tr√™n website:\n"
        f"   ‚Ä¢ {WEBSITE_URL}\n\n"
        "2Ô∏è‚É£ Nh·∫Øn tin qua Zalo OA c·ªßa c√¥ng ty ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n v√† ch·ªët ƒë∆°n:\n"
        f"   ‚Ä¢ {ZALO_OA_URL}\n\n"
        "3Ô∏è‚É£ G·ªçi hotline ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nhanh:\n"
        f"   ‚Ä¢ {HOTLINE}\n\n"
        "V·ªÅ thanh to√°n, hi·ªán c√¥ng ty h·ªó tr·ª£:\n"
        "- Thanh to√°n khi nh·∫≠n h√†ng (COD)\n"
        "- Chuy·ªÉn kho·∫£n ng√¢n h√†ng theo h∆∞·ªõng d·∫´n t·ª´ t∆∞ v·∫•n vi√™n ho·∫∑c tr√™n website."
    )


def handle_escalate_to_hotline() -> str:
    return (
        "C√¢u h·ªèi n√†y thu·ªôc nh√≥m ch√≠nh s√°ch/k·∫ø ho·∫°ch kinh doanh chuy√™n s√¢u n√™n c·∫ßn tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp ·∫°.\n\n"
        "Anh/ch·ªã vui l√≤ng ƒë·ªÉ l·∫°i:\n"
        "- H·ªç t√™n\n"
        "- S·ªë ƒëi·ªán tho·∫°i\n"
        "- M√£ TVV (n·∫øu c√≥)\n\n"
        f"Ho·∫∑c g·ªçi th·∫≥ng hotline: {HOTLINE}\n"
        "Tuy·∫øn tr√™n s·∫Ω li√™n h·ªá v√† t∆∞ v·∫•n chi ti·∫øt cho anh/ch·ªã s·ªõm nh·∫•t c√≥ th·ªÉ."
    )


def handle_channel_navigation() -> str:
    return (
        "Anh/ch·ªã c√≥ th·ªÉ theo d√µi th√¥ng tin, ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i v√† ki·∫øn th·ª©c s·ª©c kh·ªèe t·∫°i c√°c k√™nh sau:\n\n"
        f"üìò Fanpage: {FANPAGE_URL}\n"
        f"üí¨ Zalo OA: {ZALO_OA_URL}\n"
        f"üåê Website: {WEBSITE_URL}\n\n"
        "N·∫øu c·∫ßn h·ªó tr·ª£ g·∫•p, anh/ch·ªã g·ªçi tr·ª±c ti·∫øp hotline gi√∫p em nh√©."
    )


def log_conversation(payload: dict):
    if not LOG_WEBHOOK_URL:
        return
    try:
        requests.post(LOG_WEBHOOK_URL, json=payload, timeout=2)
    except Exception as e:
        print("[WARN] Log error:", e)


# =====================================================================
#   CORE handle_chat
# =====================================================================

def handle_chat(
    user_message: str,
    mode: str | None = None,
    session_id: str | None = None,
    return_meta: bool = False,
    history: List[Dict[str, Any]] | None = None,
):
    """
    Core x·ª≠ l√Ω 1 l∆∞·ª£t chat:
    - K·∫øt h·ª£p AI intent + rule-based mode
    - H·ªó tr·ª£ follow-up & duration follow-up
    - ∆Øu ti√™n combo -> s·∫£n ph·∫©m -> fallback
    """
    text = (user_message or "").strip()
    history = history or []

    if not text:
        reply = "Em ch∆∞a nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi c·ªßa anh/ch·ªã."
        meta = {
            "intent": "",
            "mode_detected": "",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    text_norm = strip_accents(text)

    # ∆Øu ti√™n rule cho case "h·ªèi cho kh√°ch"
    if is_meta_for_customer(text_norm):
        reply = (
            "√Ä, em hi·ªÉu l√† anh/ch·ªã ƒëang h·ªèi ƒë·ªÉ t∆∞ v·∫•n cho kh√°ch ·∫° üëå\n"
            "Anh/ch·ªã cho em bi·∫øt th√™m: tu·ªïi, gi·ªõi t√≠nh v√† v·∫•n ƒë·ªÅ s·ª©c kh·ªèe ch√≠nh c·ªßa kh√°ch, "
            "em s·∫Ω g·ª£i √Ω combo/s·∫£n ph·∫©m cho anh/ch·ªã d·ªÖ t∆∞ v·∫•n nh√©."
        )
        meta = {
            "intent": "meta_for_customer",
            "mode_detected": "meta_for_customer",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # D√πng history ƒë∆∞·ª£c truy·ªÅn t·ª´ /openai-chat cho AI ph√¢n lo·∫°i intent
    history_messages = history

    # G·ªçi AI ph√¢n lo·∫°i √Ω ƒë·ªãnh
    intent_info = ai_classify_intent(text, history_messages)
    intent = intent_info.get("intent", "other")
    print("[INTENT]", intent, "|", intent_info.get("reason", ""))

    # ================== ROUTING THEO INTENT T·ª∞ NHI√äN ==================
    # 1. Ch√†o h·ªèi
    if intent == "greeting":
        reply = (
            "D·∫° em ch√†o anh/ch·ªã ·∫° üòä\n"
            "Anh/ch·ªã c·ª© chia s·∫ª gi√∫p em v·∫•n ƒë·ªÅ s·ª©c kh·ªèe ho·∫∑c nhu c·∫ßu v·ªÅ s·∫£n ph·∫©m, "
            "em s·∫Ω g·ª£i √Ω combo/s·∫£n ph·∫©m ph√π h·ª£p ·∫°."
        )
        meta = {
            "intent": intent,
            "mode_detected": "greeting",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # 2. N√≥i chuy·ªán ƒë·ªùi th∆∞·ªùng / h·ªèi vu v∆°
    if intent == "smalltalk":
        smalltalk_reply = call_openai_responses(
            f"""
B·∫°n l√† tr·ª£ l√Ω s·ª©c kh·ªèe Greenway/Welllab.
Ng∆∞·ªùi d√πng ƒëang CH·ªà N√ìI CHUY·ªÜN ƒê·ªúI TH∆Ø·ªúNG, kh√¥ng y√™u c·∫ßu t∆∞ v·∫•n c·ª• th·ªÉ.

H√£y tr·∫£ l·ªùi th√¢n thi·ªán, ng·∫Øn g·ªçn (2-4 c√¢u), c√≥ th·ªÉ ƒë√πa nh·∫π, 
sau ƒë√≥ kh√©o l√©o g·ª£i √Ω r·∫±ng n·∫øu h·ªç c·∫ßn t∆∞ v·∫•n v·ªÅ s·ª©c kh·ªèe / s·∫£n ph·∫©m / combo th√¨ b·∫°n lu√¥n s·∫µn s√†ng.

C√¢u c·ªßa ng∆∞·ªùi d√πng: "{text}"
"""
        )
        meta = {
            "intent": intent,
            "mode_detected": "smalltalk",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (smalltalk_reply, meta) if return_meta else smalltalk_reply

    # 3. Ch√≠nh s√°ch / kinh doanh
    if intent == "business_policy":
        reply = handle_escalate_to_hotline()
        meta = {
            "intent": intent,
            "mode_detected": "business",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # 4. C√°ch mua h√†ng / thanh to√°n
    if intent == "buy_payment":
        reply = handle_buy_and_payment_info()
        meta = {
            "intent": intent,
            "mode_detected": "buy",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # 5. H·ªèi k√™nh li√™n h·ªá
    if intent == "channel_info":
        reply = handle_channel_navigation()
        meta = {
            "intent": intent,
            "mode_detected": "channel",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # 6. Tuning mode cho c√°c c√¢u s·ª©c kh·ªèe
    #    (gi·ªØ nguy√™n pipeline c≈©, nh∆∞ng ∆∞u ti√™n intent AI)
    if intent == "combo_question":
        mode = "combo"
    elif intent == "product_question":
        mode = "product"
    elif intent == "health_question":
        # ƒë·ªÉ auto cho pipeline combo/product t·ª± ch·ªçn
        if not mode:
            mode = "auto"

    # 7. N·∫øu l√† c√¢u follow-up ki·ªÉu "combo tr√™n / s·∫£n ph·∫©m ƒë√≥..."
    if history and looks_like_followup(text):
        reply = llm_answer_with_history(text, history)
        meta = {
            "intent": intent,
            "mode_detected": "followup",
            "health_tags": [],
            "selected_combos": [],
            "selected_products": [],
        }
        return (reply, meta) if return_meta else reply

    # 8. Rule cho duration follow-up (kh√¥ng nh·∫Øc combo tr√™n nh∆∞ng h·ªèi bao l√¢u/ li·ªáu tr√¨nh)
    extra_instruction = ""
    if history and is_duration_followup(text_norm):
        base_question = get_last_user_message_from_history(history)
        if base_question:
            # L·∫•y tags t·ª´ c√¢u h·ªèi s·ª©c kh·ªèe tr∆∞·ªõc ƒë√≥
            requested_tags_base = extract_tags_from_text(base_question)
            # D√πng c·∫£ c√¢u h·ªèi tr∆∞·ªõc + c√¢u h·ªèi hi·ªán t·∫°i
            text = (
                f"C√¢u h·ªèi tr∆∞·ªõc c·ªßa kh√°ch/t∆∞ v·∫•n vi√™n: \"{base_question}\".\n"
                f"H·ªèi ti·∫øp: \"{user_message}\"."
            )
            text_norm = strip_accents(text)
            extra_instruction = (
                "Ng∆∞·ªùi d√πng ƒëang h·ªèi ti·∫øp v·ªÅ TH·ªúI GIAN D√ôNG / LI·ªÜU TR√åNH. "
                "Trong c√¢u tr·∫£ l·ªùi, h√£y nh·∫•n m·∫°nh r√µ:\n"
                "- N√™n d√πng trong bao l√¢u th√¨ ph√π h·ª£p (theo d·ªØ li·ªáu hi·ªán c√≥).\n"
                "- N·∫øu d·ªØ li·ªáu kh√¥ng ghi r√µ, ƒë∆∞a ra g·ª£i √Ω chung chung nh∆∞ng v·∫´n an to√†n.\n"
            )
            # override tags theo c√¢u tr∆∞·ªõc
            requested_tags = requested_tags_base
        else:
            requested_tags = extract_tags_from_text(text)
    else:
        requested_tags = extract_tags_from_text(text)

    detected_mode = detect_mode(text) if not mode else mode.lower().strip()
    mode = detected_mode

    meta = {
        "intent": intent,
        "mode_detected": mode,
        "health_tags": requested_tags,
        "selected_combos": [],
        "selected_products": [],
    }

    print("[DEBUG] handle_chat mode =", mode, "| text =", text)

    # C√°c mode ƒë∆°n gi·∫£n
    if mode == "buy":
        reply = handle_buy_and_payment_info()
        return (reply, meta) if return_meta else reply

    if mode == "channel":
        reply = handle_channel_navigation()
        return (reply, meta) if return_meta else reply

    if mode == "business":
        reply = handle_escalate_to_hotline()
        return (reply, meta) if return_meta else reply

    # C√°c mode v·ªÅ s·ª©c kh·ªèe: combo / product / auto
    want_combo = "combo" in strip_accents(text) or mode == "combo"
    want_product = (
        "san pham" in strip_accents(text)
        or "s·∫£n ph·∫©m" in text.lower()
        or mode == "product"
    )

    if want_combo and not want_product:
        combos, covered_tags = select_combos_for_tags(requested_tags, text)
        meta["selected_combos"] = [c.get("id") for c in combos]
        reply = llm_answer_for_combos(
            text, requested_tags, combos, covered_tags, extra_instruction
        )
        return (reply, meta) if return_meta else reply

    if want_product and not want_combo:
        products = search_products_by_tags(requested_tags)
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(
            text, requested_tags, products, extra_instruction
        )
        return (reply, meta) if return_meta else reply

    # AUTO: ∆∞u ti√™n combo, n·∫øu kh√¥ng c√≥ th√¨ show s·∫£n ph·∫©m
    combos, covered_tags = select_combos_for_tags(requested_tags, text)
    if combos:
        meta["selected_combos"] = [c.get("id") for c in combos]
        reply = llm_answer_for_combos(
            text, requested_tags, combos, covered_tags, extra_instruction
        )
        return (reply, meta) if return_meta else reply

    products = search_products_by_tags(requested_tags)
    if products:
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(
            text, requested_tags, products, extra_instruction
        )
        return (reply, meta) if return_meta else reply

    # Kh√¥ng match g√¨
    reply = (
        "Hi·ªán em ch∆∞a t√¨m th·∫•y combo hay s·∫£n ph·∫©m n√†o ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
        f"Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n t√¨nh tr·∫°ng s·ª©c kh·ªèe, ho·∫∑c li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ k·ªπ h∆°n ·∫°."
    )
    return (reply, meta) if return_meta else reply
