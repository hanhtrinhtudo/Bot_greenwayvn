import os
import json
import time
import unicodedata
from datetime import datetime
import psycopg2
from psycopg2.extras import DictCursor

import requests
from flask import Flask, request, jsonify
from flask_cors import CORS

# ===== OpenAI SDK (Responses API) =====
try:
    from openai import OpenAI
except ImportError:
    raise Exception("Ch∆∞a c√†i openai SDK. Ch·∫°y: pip install openai")

# ===== Load ENV =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
DATABASE_URL   = os.getenv("DATABASE_URL", "")

if not OPENAI_API_KEY:
    raise Exception("Thi·∫øu bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY")

HOTLINE = os.getenv("HOTLINE", "09xx.xxx.xxx")
FANPAGE_URL = os.getenv("FANPAGE_URL", "https://facebook.com/ten-fanpage")
ZALO_OA_URL = os.getenv("ZALO_OA_URL", "https://zalo.me/ten-oa")
WEBSITE_URL = os.getenv("WEBSITE_URL", "https://greenwayglobal.vn")

LOG_WEBHOOK_URL = os.getenv("LOG_WEBHOOK_URL", "")  # üëà Webhook Apps Script

# ===== Init App =====
app = Flask(__name__)
CORS(app)  # Cho ph√©p web / Conversational Agents g·ªçi API kh√¥ng b·ªã CORS

client = OpenAI(api_key=OPENAI_API_KEY)

# ====== DB HELPER ======
def get_db_conn():
    # Render khuy·∫øn ngh·ªã d√πng 1 connection / process
    # n√™n c√≥ th·ªÉ cache connection ·ªü global n·∫øu mu·ªën t·ªëi ∆∞u h∆°n
    return psycopg2.connect(DATABASE_URL, cursor_factory=DictCursor)

def get_recent_history(session_id: str, limit: int = 8):
    """L·∫•y l·ªãch s·ª≠ g·∫ßn nh·∫•t c·ªßa 1 phi√™n chat (user + assistant)."""
    if not session_id:
        return []

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT role, content
                FROM chat_logs
                WHERE session_id = %s
                ORDER BY created_at DESC
                LIMIT %s
                """,
                (session_id, limit),
            )
            rows = cur.fetchall()
        # ƒë·∫£o ng∆∞·ª£c l·∫°i theo th·ª© t·ª± c≈©
        rows = list(reversed(rows))
        return [{"role": r["role"], "content": r["content"]} for r in rows]
    finally:
        conn.close()

def save_message(session_id: str, role: str, content: str):
    """L∆∞u 1 message v√†o DB."""
    if not session_id or not content:
        return

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO chat_logs (session_id, role, content)
                VALUES (%s, %s, %s)
                """,
                (session_id, role, content),
            )
        conn.commit()
    finally:
        conn.close()

# >>> M·ªöI: h√†m nh·∫≠n di·ªán c√¢u ‚Äútr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n‚Äù
def strip_accents(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if not unicodedata.combining(ch))
    return text

def is_retry_phrase(text: str) -> bool:
    """
    Nh·∫≠n di·ªán c√°c c√¢u ki·ªÉu:
    - 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n'
    - 'tr·∫£ l·ªùi l·∫°i c√¢u v·ª´a r·ªìi'
    - 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr∆∞·ªõc'
    """
    t = strip_accents((text or "").strip())
    if not t:
        return False

    patterns = [
        "tra loi lai cau hoi tren",
        "tra loi lai cau hoi vua roi",
        "tra loi lai cau vua roi",
        "tra loi lai cau truoc",
        "tra loi lai cau hoi truoc",
        "tra loi lai cau hoi nay",
        "tra loi lai cau hoi luc nay",
    ]
    return any(p in t for p in patterns)

def get_last_user_question_for_retry(session_id: str) -> str | None:
    """
    L·∫•y c√¢u h·ªèi user g·∫ßn nh·∫•t (role='user') nh∆∞ng KH√îNG ph·∫£i c√°c c√¢u 'tr·∫£ l·ªùi l·∫°i...'
    d√πng cho t√¨nh hu·ªëng retry.
    """
    history = get_recent_history(session_id, limit=20)
    # Duy·ªát t·ª´ cu·ªëi l√™n ƒë·∫ßu ƒë·ªÉ l·∫•y c√¢u g·∫ßn nh·∫•t
    for msg in reversed(history):
        if msg.get("role") == "user" and not is_retry_phrase(msg.get("content", "")):
            return msg.get("content")
    return None
    
# =====================================================================
#   LOAD D·ªÆ LI·ªÜU JSON
# =====================================================================
def load_json_file(path, default=None):
    if default is None:
        default = {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"[WARN] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file {path}: {e}")
        return default


PRODUCTS_DATA = load_json_file("products.json", {"products": []})
COMBOS_DATA = load_json_file("combos.json", {"combos": []})
HEALTH_TAGS_CONFIG = load_json_file("health_tags_config.json", {})
COMBOS_META = load_json_file("combos_meta.json", {})
MULTI_ISSUE_RULES = load_json_file("multi_issue_rules.json", {"rules": []})

PRODUCTS = PRODUCTS_DATA.get("products", [])
COMBOS = COMBOS_DATA.get("combos", [])

def strip_accents(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if not unicodedata.combining(ch))
    return text


def extract_tags_from_text(text: str):
    """D·ª±a tr√™n HEALTH_TAGS_CONFIG, map c√¢u h·ªèi sang health_tags."""
    text_norm = strip_accents(text)
    found = set()

    for tag, cfg in HEALTH_TAGS_CONFIG.items():
        for syn in cfg.get("synonyms", []):
            syn_norm = strip_accents(syn)
            if syn_norm and syn_norm in text_norm:
                found.add(tag)
                break
    return list(found)


def apply_multi_issue_rules(text: str):
    """Th·ª≠ match c√°c rule nhi·ªÅu v·∫•n ƒë·ªÅ trong multi_issue_rules."""
    text_norm = strip_accents(text)
    best_rule = None
    best_count = 0

    for rule in MULTI_ISSUE_RULES.get("rules", []):
        match_phrases = rule.get("match_phrases", [])
        count = 0
        for phrase in match_phrases:
            if strip_accents(phrase) in text_norm:
                count += 1
        if count > best_count and count > 0:
            best_count = count
            best_rule = rule

    return best_rule


def score_combo_for_tags(combo, requested_tags):
    requested_tags = set(requested_tags)
    combo_tags = set(combo.get("health_tags", []))
    intersection = requested_tags & combo_tags
    score = 0

    # M·ªói tag tr√πng +3 ƒëi·ªÉm
    score += 3 * len(intersection)

    # ∆Øu ti√™n combo core/support
    meta = COMBOS_META.get(combo.get("id", ""), {})
    role = meta.get("role", "core")
    if role == "core":
        score += 2
    elif role == "support":
        score += 1

    # Th√™m weight theo t·ªâ l·ªá ph·ªß
    if combo_tags and requested_tags:
        overlap_ratio = len(intersection) / len(requested_tags)
        score += overlap_ratio

    return score, list(intersection)


def select_combos_for_tags(requested_tags, user_text):
    """Ch·ªçn 1‚Äì3 combo ph√π h·ª£p nh·∫•t v·ªõi t·∫≠p requested_tags."""
    if not requested_tags and user_text:
        requested_tags = extract_tags_from_text(user_text)

    requested_tags = list(set(requested_tags))
    if not requested_tags:
        return [], []

    # ∆Øu ti√™n rule nhi·ªÅu √Ω n·∫øu match
    rule = apply_multi_issue_rules(user_text or "")
    if rule:
        candidate_ids = set(rule.get("recommended_combos", []))
        candidates = [c for c in COMBOS if c.get("id") in candidate_ids]
    else:
        candidates = COMBOS

    scored = []
    for combo in candidates:
        s, matched = score_combo_for_tags(combo, requested_tags)
        if s > 0:
            scored.append((s, combo, matched))

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[:3]

    selected_combos = [item[1] for item in top]
    covered_tags = set()
    for _, _, matched in top:
        covered_tags.update(matched)

    return selected_combos, list(covered_tags)


def search_products_by_tags(requested_tags, limit=5):
    requested_tags = set(requested_tags)
    if not requested_tags:
        return []

    results = []
    for p in PRODUCTS:
        tags = set(p.get("health_tags") or [])
        group = p.get("group")  # group: gan, tieu_hoa, than, tim_mach...
        if group:
            tags.add(group)
        if tags & requested_tags:
            results.append(p)

    return results[:limit]


def call_openai_responses(prompt_text: str) -> str:
    """G·ªçi Responses API gi·ªëng style d·ª± √°n c≈© c·ªßa anh."""
    try:
        res = client.responses.create(
            model="gpt-4.1-mini",
            input=prompt_text,
        )
        reply_text = getattr(res, "output_text", "") or ""
        reply_text = reply_text.strip()
        if not reply_text:
            reply_text = "Hi·ªán t·∫°i em kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ h·ªá th·ªëng OpenAI."
        return reply_text
    except Exception as e:
        print("‚ùå ERROR OpenAI Responses:", e)
        return (
            "Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng AI ƒëang g·∫∑p l·ªói, anh/ch·ªã vui l√≤ng th·ª≠ l·∫°i sau "
            "ho·∫∑c li√™n h·ªá hotline ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp."
        )


def llm_answer_for_combos(user_question, requested_tags, combos, covered_tags):
    if not combos:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y combo ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n t∆∞ v·∫•n chi ti·∫øt h∆°n ·∫°."
        )

    combos_json = json.dumps(combos, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu combo v√† s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

D∆∞·ªõi ƒë√¢y l√† c√¢u h·ªèi v√† d·ªØ li·ªáu:

- C√¢u h·ªèi c·ªßa kh√°ch / t∆∞ v·∫•n vi√™n: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe h·ªá th·ªëng tr√≠ch xu·∫•t ƒë∆∞·ª£c: {tags_text}

D·ªØ li·ªáu c√°c combo ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{combos_json}

Y√äU C·∫¶U TR·∫¢ L·ªúI (b·∫±ng ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu, r√µ r√†ng):

1. M·ªü ƒë·∫ßu 1‚Äì3 c√¢u: t√≥m t·∫Øt c√°c v·∫•n ƒë·ªÅ/nhu c·∫ßu ch√≠nh v√† ƒë·ªãnh h∆∞·ªõng x·ª≠ l√Ω (theo combo) cho kh√°ch.
2. V·ªõi t·ª´ng combo:
   - N√™u r√µ combo n√†y h·ªó tr·ª£ nh·ªØng v·∫•n ƒë·ªÅ n√†o trong c√°c v·∫•n ƒë·ªÅ kh√°ch ƒëang g·∫∑p.
   - Li·ªát k√™ t·ª´ng s·∫£n ph·∫©m trong combo:
     + T√™n s·∫£n ph·∫©m
     + L·ª£i √≠ch ch√≠nh / t√°c d·ª•ng h·ªó tr·ª£
     + Th·ªùi gian d√πng g·ª£i √Ω (n·∫øu c√≥ trong d·ªØ li·ªáu)
     + C√°ch d√πng t√≥m t·∫Øt (d·ª±a tr√™n dose_text/usage_text n·∫øu c√≥)
     + Gi√° (price_text)
     + Link s·∫£n ph·∫©m (product_url)
3. N·∫øu v·∫•n ƒë·ªÅ c√≥ v·∫ª n·∫∑ng/nh·∫°y c·∫£m (ung th∆∞, tim m·∫°ch n·∫∑ng, suy th·∫≠n, v.v.) h√£y khuy·∫øn ngh·ªã kh√°ch n√™n thƒÉm kh√°m v√† t√°i kh√°m ƒë·ªãnh k·ª≥.
4. Cu·ªëi c√¢u tr·∫£ l·ªùi, lu√¥n nh·∫Øc: "S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.".
5. Vi·∫øt gi·ªçng ƒëi·ªáu g·∫ßn g≈©i, l·ªãch s·ª±, h∆∞·ªõng d·∫´n nh∆∞ ƒëang n√≥i chuy·ªán v·ªõi t∆∞ v·∫•n vi√™n/kh√°ch h√†ng th·∫≠t.
"""
    return call_openai_responses(prompt)


def llm_answer_for_products(user_question, requested_tags, products):
    if not products:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n r√µ h∆°n ·∫°."
        )

    products_json = json.dumps(products, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

- C√¢u h·ªèi: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe: {tags_text}

D·ªØ li·ªáu c√°c s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{products_json}

Y√äU C·∫¶U TR·∫¢ L·ªúI:

1. M·ªü ƒë·∫ßu 1‚Äì2 c√¢u: gi·ªõi thi·ªáu ƒë√¢y l√† c√°c s·∫£n ph·∫©m h·ªó tr·ª£ ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ m√† kh√°ch ƒëang g·∫∑p.
2. V·ªõi t·ª´ng s·∫£n ph·∫©m:
   - T√™n s·∫£n ph·∫©m
   - V·∫•n ƒë·ªÅ ch√≠nh m√† s·∫£n ph·∫©m h·ªó tr·ª£ (d·ª±a tr√™n group/health_tags)
   - L·ª£i √≠ch ch√≠nh (d·ª±a tr√™n benefits_text ho·∫∑c m√¥ t·∫£)
   - C√°ch d√πng t√≥m t·∫Øt (usage_text ho·∫∑c dose_text n·∫øu c√≥)
   - Gi√° (price_text)
   - Link s·∫£n ph·∫©m (product_url)
3. Cu·ªëi c√πng nh·∫Øc: s·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.
4. Vi·∫øt ng·∫Øn g·ªçn, r√µ r√†ng, d·ªÖ d√πng cho t∆∞ v·∫•n vi√™n khi ch√°t v·ªõi kh√°ch.
"""
    return call_openai_responses(prompt)


def handle_buy_and_payment_info():
    return (
        "ƒê·ªÉ mua h√†ng, anh/ch·ªã c√≥ th·ªÉ ch·ªçn m·ªôt trong c√°c c√°ch sau:\n\n"
        "1Ô∏è‚É£ ƒê·∫∑t h√†ng tr·ª±c ti·∫øp tr√™n website:\n"
        f"   ‚Ä¢ {WEBSITE_URL}\n\n"
        "2Ô∏è‚É£ Nh·∫Øn tin qua Zalo OA c·ªßa c√¥ng ty ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n v√† ch·ªët ƒë∆°n:\n"
        f"   ‚Ä¢ {ZALO_OA_URL}\n\n"
        "3Ô∏è‚É£ G·ªçi hotline ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nhanh:\n"
        f"   ‚Ä¢ {HOTLINE}\n\n"
        "V·ªÅ thanh to√°n, hi·ªán c√¥ng ty h·ªó tr·ª£:\n"
        "- Thanh to√°n khi nh·∫≠n h√†ng (COD)\n"
        "- Chuy·ªÉn kho·∫£n ng√¢n h√†ng theo h∆∞·ªõng d·∫´n t·ª´ t∆∞ v·∫•n vi√™n ho·∫∑c tr√™n website."
    )


def handle_escalate_to_hotline():
    return (
        "C√¢u h·ªèi n√†y thu·ªôc nh√≥m ch√≠nh s√°ch/k·∫ø ho·∫°ch kinh doanh chuy√™n s√¢u n√™n c·∫ßn tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp ·∫°.\n\n"
        "Anh/ch·ªã vui l√≤ng ƒë·ªÉ l·∫°i:\n"
        "- H·ªç t√™n\n"
        "- S·ªë ƒëi·ªán tho·∫°i\n"
        "- M√£ TVV (n·∫øu c√≥)\n\n"
        f"Ho·∫∑c g·ªçi th·∫≥ng hotline: {HOTLINE}\n"
        "Tuy·∫øn tr√™n s·∫Ω li√™n h·ªá v√† t∆∞ v·∫•n chi ti·∫øt cho anh/ch·ªã s·ªõm nh·∫•t c√≥ th·ªÉ."
    )


def handle_channel_navigation():
    return (
        "Anh/ch·ªã c√≥ th·ªÉ theo d√µi th√¥ng tin, ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i v√† ki·∫øn th·ª©c s·ª©c kh·ªèe t·∫°i c√°c k√™nh sau:\n\n"
        f"üìò Fanpage: {FANPAGE_URL}\n"
        f"üí¨ Zalo OA: {ZALO_OA_URL}\n"
        f"üåê Website: {WEBSITE_URL}\n\n"
        "N·∫øu c·∫ßn h·ªó tr·ª£ g·∫•p, anh/ch·ªã g·ªçi tr·ª±c ti·∫øp hotline gi√∫p em nh√©."
    )


def detect_mode(user_message: str) -> str:
    """ƒêo√°n xem user ƒëang h·ªèi v·ªÅ combo / s·∫£n ph·∫©m / mua h√†ng / k√™nh / kinh doanh."""
    text_norm = strip_accents(user_message)

    # H·ªèi kinh doanh, ch√≠nh s√°ch, hoa h·ªìng
    business_keywords = [
        "chinh sach", "hoa hong", "tuyen dung", "len cap",
        "leader", "doanh so", "muc tieu thang"
    ]
    if any(k in text_norm for k in business_keywords):
        return "business"

    # H·ªèi mua h√†ng / thanh to√°n
    buy_keywords = [
        "mua", "dat hang", "thanh toan", "ship", "giao hang", "dat mua"
    ]
    if any(k in text_norm for k in buy_keywords):
        return "buy"

    # H·ªèi k√™nh, fanpage, zalo
    channel_keywords = [
        "fanpage", "zalo", "kenh", "website", "trang web"
    ]
    if any(k in text_norm for k in channel_keywords):
        return "channel"

    # Nh·∫Øc ƒë·∫øn combo / s·∫£n ph·∫©m
    if "combo" in text_norm:
        return "combo"
    if "san pham" in text_norm or "s·∫£n ph·∫©m" in user_message.lower():
        return "product"

    return "auto"

# =====================================================================
#   LOG CONVERSATION ‚Üí GOOGLE SHEETS
# =====================================================================
def log_conversation(payload: dict):
    if not LOG_WEBHOOK_URL:
        return
    try:
        requests.post(LOG_WEBHOOK_URL, json=payload, timeout=2)
    except Exception as e:
        print("[WARN] Log error:", e)

def handle_chat(user_message: str, mode: str | None = None, return_meta: bool = False):
    text = (user_message or "").strip()
    if not text:
        reply = "Em ch∆∞a nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi c·ªßa anh/ch·ªã."
        if return_meta:
            meta = {
                "mode_detected": "",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
            }
            return reply, meta
        return reply

    detected_mode = detect_mode(text) if not mode else mode.lower().strip()
    mode = detected_mode

    # meta m·∫∑c ƒë·ªãnh
    requested_tags = extract_tags_from_text(text)
    meta = {
        "mode_detected": mode,
        "health_tags": requested_tags,
        "selected_combos": [],
        "selected_products": [],
    }
    
    # üëá TH√äM D√íNG N√ÄY
    print("[DEBUG] handle_chat mode =", mode, "| text =", text)
    
    # C√°c mode ƒë∆°n gi·∫£n
    if mode == "buy":
        reply = handle_buy_and_payment_info()
        if return_meta:
            return reply, meta
        return reply

    if mode == "channel":
        reply = handle_channel_navigation()
        if return_meta:
            return reply, meta
        return reply

    if mode == "business":
        reply = handle_escalate_to_hotline()
        if return_meta:
            return reply, meta
        return reply

    # C√°c mode v·ªÅ s·ª©c kh·ªèe: combo / product / auto
    want_combo = "combo" in strip_accents(text) or mode == "combo"
    want_product = "san pham" in strip_accents(text) or "s·∫£n ph·∫©m" in text.lower() or mode == "product"

    if want_combo and not want_product:
        combos, covered_tags = select_combos_for_tags(requested_tags, text)
        meta["selected_combos"] = [c.get("id") for c in combos]
        reply = llm_answer_for_combos(text, requested_tags, combos, covered_tags)
        if return_meta:
            return reply, meta
        return reply

    if want_product and not want_combo:
        products = search_products_by_tags(requested_tags)
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(text, requested_tags, products)
        if return_meta:
            return reply, meta
        return reply

    # AUTO: ∆∞u ti√™n combo, n·∫øu kh√¥ng c√≥ th√¨ show s·∫£n ph·∫©m
    combos, covered_tags = select_combos_for_tags(requested_tags, text)
    if combos:
        meta["selected_combos"] = [c.get("id") for c in combos]
        reply = llm_answer_for_combos(text, requested_tags, combos, covered_tags)
        if return_meta:
            return reply, meta
        return reply

    products = search_products_by_tags(requested_tags)
    if products:
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(text, requested_tags, products)
        if return_meta:
            return reply, meta
        return reply

    # Kh√¥ng match g√¨
    reply = (
        "Hi·ªán em ch∆∞a t√¨m th·∫•y combo hay s·∫£n ph·∫©m n√†o ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
        f"Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n t√¨nh tr·∫°ng s·ª©c kh·ªèe, ho·∫∑c li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ k·ªπ h∆°n ·∫°."
    )
    if return_meta:
        return reply, meta
    return reply

@app.route("/openai-chat", methods=["POST"])
def openai_chat():
    start_time = time.time()
    try:
        body = request.get_json(force=True) or {}

        user_message = (body.get("message") or "").strip()
        mode = (
            (body.get("mode") or "").strip().lower()
            if isinstance(body, dict)
            else ""
        )
        session_id = body.get("session_id") or ""
        channel = body.get("channel") or "web"
        user_id = body.get("user_id") or ""

        # N·∫øu client kh√¥ng g·ª≠i session_id, t·ª± sinh t·∫°m
        if not session_id:
            session_id = f"web-{request.remote_addr}-{int(time.time())}"

        # 1) L∆∞u message g·ªëc c·ªßa user
        try:
            save_message(session_id, "user", user_message)
        except Exception as e:
            print("[DB ERROR] Cannot save user message:", e)

        # 2) Ki·ªÉm tra xem user c√≥ y√™u c·∫ßu 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n' kh√¥ng
        message_for_ai = user_message
        used_history_message = ""
        if looks_like_repeat_request(user_message):
            last_q = get_last_user_message(session_id)
            if last_q:
                used_history_message = last_q
                message_for_ai = last_q
                print(
                    "[DEBUG] Repeat request detected. Using last user question from history:",
                    last_q,
                )

        # 3) X·ª≠ l√Ω chat (combo/product/auto/business/buy/channel)
        reply_text, meta = handle_chat(
            message_for_ai, mode or None, return_meta=True
        )

        # 4) L∆∞u bot reply v√†o DB
        try:
            save_message(session_id, "assistant", reply_text)
        except Exception as e:
            print("[DB ERROR] Cannot save bot reply:", e)

        latency_ms = int((time.time() - start_time) * 1000)

        log_payload = {
            "timestamp": datetime.utcnow().isoformat(),
            "channel": channel,
            "session_id": session_id,
            "user_id": user_id,
            "user_message": user_message,
            "effective_message": effective_message,  # üëà xem Bot ƒë√£ d√πng c√¢u n√†o ƒë·ªÉ x·ª≠ l√Ω
            "retry_used": retry_used,
            "bot_reply": reply_text,
            "mode_detected": meta.get("mode_detected"),
            "health_tags": meta.get("health_tags", []),
            "selected_combos": meta.get("selected_combos", []),
            "selected_products": meta.get("selected_products", []),
            "latency_ms": latency_ms,
        }
        log_conversation(log_payload)

        return jsonify({"reply": reply_text})

    except Exception as e:
        print("‚ùå ERROR /openai-chat:", e)
        return jsonify({
            "reply": "Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng ƒëang g·∫∑p l·ªói. Anh/ch·ªã vui l√≤ng th·ª≠ l·∫°i sau nh√©."
        }), 500


@app.route("/", methods=["GET"])
def home():
    return "üî• Greenway / Welllab Chatbot Gateway ƒëang ch·∫°y ngon l√†nh!", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)

