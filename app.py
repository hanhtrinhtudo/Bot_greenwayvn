import os
import json
import time
import unicodedata
from datetime import datetime

import psycopg2
from psycopg2.extras import DictCursor

import requests
from flask import Flask, request, jsonify
from flask_cors import CORS

# ===== OpenAI SDK (Responses API) =====
try:
    from openai import OpenAI
except ImportError:
    raise Exception("Ch∆∞a c√†i openai SDK. Ch·∫°y: pip install openai")

# ===== Load ENV =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
DATABASE_URL = os.getenv("DATABASE_URL", "")

if not OPENAI_API_KEY:
    raise Exception("Thi·∫øu bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY")

HOTLINE = os.getenv("HOTLINE", "09xx.xxx.xxx")
FANPAGE_URL = os.getenv("FANPAGE_URL", "https://facebook.com/ten-fanpage")
ZALO_OA_URL = os.getenv("ZALO_OA_URL", "https://zalo.me/ten-oa")
WEBSITE_URL = os.getenv("WEBSITE_URL", "https://greenwayglobal.vn")

LOG_WEBHOOK_URL = os.getenv("LOG_WEBHOOK_URL", "")  # Webhook Apps Script
ADMIN_SECRET = os.getenv("ADMIN_SECRET", "")  # d√πng chung cho /admin/*

# ===== Init App =====
app = Flask(__name__)
CORS(app)  # Cho ph√©p web / Conversational Agents g·ªçi API kh√¥ng b·ªã CORS

client = OpenAI(api_key=OPENAI_API_KEY)

# =====================================================================
#   DB ‚Äì QU·∫¢N L√ù TVV (H·ªí S∆† T∆Ø V·∫§N VI√äN)
# =====================================================================
def upsert_tvv_user(tvv_code: str, full_name: str, phone: str, email: str, company_name: str):
    """
    T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t h·ªì s∆° TVV theo tvv_code.
    """
    if not tvv_code or not full_name:
        raise ValueError("Thi·∫øu tvv_code ho·∫∑c full_name")

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO tvv_users (tvv_code, full_name, phone, email, company_name)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (tvv_code)
                DO UPDATE SET
                  full_name    = EXCLUDED.full_name,
                  phone        = EXCLUDED.phone,
                  email        = EXCLUDED.email,
                  company_name = EXCLUDED.company_name,
                  updated_at   = NOW()
                """,
                (tvv_code, full_name, phone, email, company_name),
            )
        conn.commit()
    finally:
        conn.close()


def list_tvv_users(q: str = "", limit: int = 200):
    """
    L·∫•y danh s√°ch TVV cho trang admin (c√≥ search q).
    """
    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            if q:
                pattern = f"%{q}%"
                cur.execute(
                    """
                    SELECT tvv_code, full_name, phone, email, company_name, created_at, updated_at
                    FROM tvv_users
                    WHERE
                      tvv_code ILIKE %s OR
                      full_name ILIKE %s OR
                      phone ILIKE %s OR
                      email ILIKE %s OR
                      company_name ILIKE %s
                    ORDER BY created_at DESC
                    LIMIT %s
                    """,
                    (pattern, pattern, pattern, pattern, pattern, limit),
                )
            else:
                cur.execute(
                    """
                    SELECT tvv_code, full_name, phone, email, company_name, created_at, updated_at
                    FROM tvv_users
                    ORDER BY created_at DESC
                    LIMIT %s
                    """,
                    (limit,),
                )
            rows = cur.fetchall()
        return [dict(r) for r in rows]
    finally:
        conn.close()

# =====================================================================
#   DB HELPER ‚Äì K·∫æT N·ªêI & L·ªäCH S·ª¨ H·ªòI THO·∫†I
# =====================================================================
def get_db_conn():
    """
    M·ªü connection t·ªõi PostgreSQL (Render cung c·∫•p DATABASE_URL).
    """
    if not DATABASE_URL:
        raise Exception("Thi·∫øu bi·∫øn m√¥i tr∆∞·ªùng DATABASE_URL")
    return psycopg2.connect(DATABASE_URL, cursor_factory=DictCursor)


def get_recent_history(session_id: str, limit: int = 8):
    """
    L·∫•y l·ªãch s·ª≠ g·∫ßn nh·∫•t c·ªßa 1 phi√™n chat (user + assistant).
    K·∫øt qu·∫£: list [{role, content}], ƒë√£ sort t·ª´ c≈© -> m·ªõi.
    """
    if not session_id:
        return []

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT role, content
                FROM chat_logs
                WHERE session_id = %s
                ORDER BY created_at DESC
                LIMIT %s
                """,
                (session_id, limit),
            )
            rows = cur.fetchall()
        rows = list(reversed(rows))  # ƒë·∫£o l·∫°i theo th·ª© t·ª± c≈©
        return [{"role": r["role"], "content": r["content"]} for r in rows]
    finally:
        conn.close()


def save_message(session_id: str, role: str, content: str):
    """
    L∆∞u 1 message v√†o DB (n·∫øu c√≥ session_id & content).
    """
    if not session_id or not content:
        return

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO chat_logs (session_id, role, content)
                VALUES (%s, %s, %s)
                """,
                (session_id, role, content),
            )
        conn.commit()
    finally:
        conn.close()


def get_last_user_message(session_id: str):
    """
    L·∫•y c√¢u h·ªèi g·∫ßn nh·∫•t c·ªßa USER trong 1 session.
    D√πng cho c√°c c√¢u ki·ªÉu: 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n'.
    """
    if not session_id:
        return None

    conn = get_db_conn()
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT content
                FROM chat_logs
                WHERE session_id = %s AND role = 'user'
                ORDER BY created_at DESC
                LIMIT 1
                """,
                (session_id,),
            )
            row = cur.fetchone()
            return row["content"] if row else None
    finally:
        conn.close()

# =====================================================================
#   TI·ªÜN √çCH X·ª¨ L√ù TEXT
# =====================================================================
def strip_accents(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if not unicodedata.combining(ch))
    return text


def looks_like_repeat_request(text: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u ki·ªÉu: 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n / v·ª´a n√£y'.
    """
    if not text:
        return False
    t = strip_accents(text)
    t = " ".join(t.split())

    patterns = [
        "tra loi lai cau hoi",
        "tra loi lai cau tren",
        "tra loi lai cau vua nay",
        "tra loi lai cau truoc",
        "hoi lai cau hoi truoc",
        "hoi lai cau truoc",
    ]
    return any(p in t for p in patterns)


def looks_like_followup(text: str) -> bool:
    """
    Nh·∫≠n di·ªán c√¢u follow-up d·ª±a tr√™n c√¢u tr·∫£ l·ªùi tr∆∞·ªõc:
    'combo tr√™n u·ªëng bao l√¢u', 's·∫£n ph·∫©m ƒë√≥ gi√° bao nhi√™u', ...
    """
    if not text:
        return False
    t = strip_accents(text)
    t = " ".join(t.split())

    # Nh·∫Øc 'combo / s·∫£n ph·∫©m / g√≥i' + 'tr√™n / ƒë√≥ / v·ª´a n√£y / tr∆∞·ªõc'
    core_phrases = [
        "combo tren",
        "combo truoc",
        "combo vua nay",
        "combo do",
        "san pham tren",
        "san pham truoc",
        "san pham vua nay",
        "san pham do",
        "goi tren",
        "goi truoc",
        "goi vua nay",
        "goi do",
    ]
    if any(p in t for p in core_phrases):
        return True

    # C√¢u h·ªèi v·ªÅ th·ªùi gian u·ªëng / li·ªÅu / gi√° m√† th∆∞·ªùng l√† follow-up
    if "bao lau" in t and ("uong" in t or "dung" in t):
        return True
    if "gia bao nhieu" in t or "gia the nao" in t:
        return True
    if "moi lan uong" in t or "ngay uong" in t or "cach uong" in t or "cach dung" in t:
        return True

    return False

# =====================================================================
#   LOAD D·ªÆ LI·ªÜU JSON
# =====================================================================
def load_json_file(path, default=None):
    if default is None:
        default = {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"[WARN] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file {path}: {e}")
        return default


PRODUCTS_DATA = load_json_file("products.json", {"products": []})
COMBOS_DATA = load_json_file("combos.json", {"combos": []})
HEALTH_TAGS_CONFIG = load_json_file("health_tags_config.json", {})
COMBOS_META = load_json_file("combos_meta.json", {})
MULTI_ISSUE_RULES = load_json_file("multi_issue_rules.json", {"rules": []})

PRODUCTS = PRODUCTS_DATA.get("products", [])
COMBOS = COMBOS_DATA.get("combos", [])

# =====================================================================
#   TAG & SELECTION
# =====================================================================
def extract_tags_from_text(text: str):
    """D·ª±a tr√™n HEALTH_TAGS_CONFIG, map c√¢u h·ªèi sang health_tags."""
    text_norm = strip_accents(text)
    found = set()

    for tag, cfg in HEALTH_TAGS_CONFIG.items():
        for syn in cfg.get("synonyms", []):
            syn_norm = strip_accents(syn)
            if syn_norm and syn_norm in text_norm:
                found.add(tag)
                break
    return list(found)


def apply_multi_issue_rules(text: str):
    """Th·ª≠ match c√°c rule nhi·ªÅu v·∫•n ƒë·ªÅ trong multi_issue_rules."""
    text_norm = strip_accents(text)
    best_rule = None
    best_count = 0

    for rule in MULTI_ISSUE_RULES.get("rules", []):
        match_phrases = rule.get("match_phrases", [])
        count = 0
        for phrase in match_phrases:
            if strip_accents(phrase) in text_norm:
                count += 1
        if count > best_count and count > 0:
            best_count = count
            best_rule = rule

    return best_rule


def score_combo_for_tags(combo, requested_tags):
    requested_tags = set(requested_tags)
    combo_tags = set(combo.get("health_tags", []))
    intersection = requested_tags & combo_tags
    score = 0

    # M·ªói tag tr√πng +3 ƒëi·ªÉm
    score += 3 * len(intersection)

    # ∆Øu ti√™n combo core/support
    meta = COMBOS_META.get(combo.get("id", ""), {})
    role = meta.get("role", "core")
    if role == "core":
        score += 2
    elif role == "support":
        score += 1

    # Th√™m weight theo t·ªâ l·ªá ph·ªß
    if combo_tags and requested_tags:
        overlap_ratio = len(intersection) / len(requested_tags)
        score += overlap_ratio

    return score, list(intersection)


def select_combos_for_tags(requested_tags, user_text):
    """Ch·ªçn 1‚Äì3 combo ph√π h·ª£p nh·∫•t v·ªõi t·∫≠p requested_tags."""
    if not requested_tags and user_text:
        requested_tags = extract_tags_from_text(user_text)

    requested_tags = list(set(requested_tags))
    if not requested_tags:
        return [], []

    # ∆Øu ti√™n rule nhi·ªÅu √Ω n·∫øu match
    rule = apply_multi_issue_rules(user_text or "")
    if rule:
        candidate_ids = set(rule.get("recommended_combos", []))
        candidates = [c for c in COMBOS if c.get("id") in candidate_ids]
    else:
        candidates = COMBOS

    scored = []
    for combo in candidates:
        s, matched = score_combo_for_tags(combo, requested_tags)
        if s > 0:
            scored.append((s, combo, matched))

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[:3]

    selected_combos = [item[1] for item in top]
    covered_tags = set()
    for _, _, matched in top:
        covered_tags.update(matched)

    return selected_combos, list(covered_tags)


def search_products_by_tags(requested_tags, limit=5):
    requested_tags = set(requested_tags)
    if not requested_tags:
        return []

    results = []
    for p in PRODUCTS:
        tags = set(p.get("health_tags") or [])
        group = p.get("group")  # group: gan, tieu_hoa, than, tim_mach...
        if group:
            tags.add(group)
        if tags & requested_tags:
            results.append(p)

    return results[:limit]

def search_products_by_groups(groups, limit=5):
    """
    Ch·ªçn s·∫£n ph·∫©m theo group (tieu_hoa, gan, than, ...),
    d√πng khi health_tags kh√¥ng match nh∆∞ng AI ƒë√£ g·ª£i √Ω nh√≥m.
    """
    group_set = {g for g in (groups or []) if g}
    if not group_set:
        return []

    results = []
    for p in PRODUCTS:
        g = p.get("group")
        if g and g in group_set:
            results.append(p)

    return results[:limit]

# =====================================================================
#   OPENAI RESPONSES
# =====================================================================
def call_openai_responses(prompt_text: str) -> str:
    """G·ªçi Responses API gi·ªëng style d·ª± √°n c≈© c·ªßa anh."""
    try:
        res = client.responses.create(
            model="gpt-4.1-mini",
            input=prompt_text,
        )
        reply_text = getattr(res, "output_text", "") or ""
        reply_text = reply_text.strip()
        if not reply_text:
            reply_text = "Hi·ªán t·∫°i em kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ h·ªá th·ªëng OpenAI."
        return reply_text
    except Exception as e:
        print("‚ùå ERROR OpenAI Responses:", e)
        return (
            "Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng AI ƒëang g·∫∑p l·ªói, anh/ch·ªã vui l√≤ng th·ª≠ l·∫°i sau "
            "ho·∫∑c li√™n h·ªá hotline ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp."
        )


def safe_parse_json(text: str, default=None):
    """C·ªë g·∫Øng b√≥c JSON t·ª´ c√¢u tr·∫£ l·ªùi c·ªßa model."""
    if default is None:
        default = {}
    if not text:
        return default
    try:
        return json.loads(text)
    except Exception:
        # Th·ª≠ b√≥c t·ª´ { ... }
        try:
            start = text.find("{")
            end = text.rfind("}")
            if start != -1 and end != -1 and end > start:
                return json.loads(text[start:end+1])
        except Exception:
            return default
    return default


def ai_classify_intent(
    user_message: str, history_messages: list[dict] | None = None
) -> dict:
    """
    Ph√¢n lo·∫°i √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng:
    - greeting: ch√†o h·ªèi
    - smalltalk: n√≥i chuy·ªán linh tinh, h·ªèi thƒÉm, c√¢u ƒë·ªùi th∆∞·ªùng
    - health_question: h·ªèi v·ªÅ v·∫•n ƒë·ªÅ s·ª©c kh·ªèe chung (ch∆∞a r√µ combo/s·∫£n ph·∫©m)
    - product_question: h·ªèi v·ªÅ 1 s·∫£n ph·∫©m c·ª• th·ªÉ
    - combo_question: h·ªèi g·ª£i √Ω combo
    - business_policy: ch√≠nh s√°ch / hoa h·ªìng / tuy·ªÉn d·ª•ng
    - buy_payment: c√°ch mua h√†ng, thanh to√°n, giao h√†ng
    - channel_info: h·ªèi link fanpage, zalo, website
    - other: kh√¥ng r√µ / ch·ªß ƒë·ªÅ kh√°c
    """
    history_messages = history_messages or []
    # Gh√©p l·ªãch s·ª≠ th√†nh text
    history_text_lines = []
    for m in history_messages[-6:]:  # l·∫•y t·ªëi ƒëa 6 c√¢u g·∫ßn nh·∫•t
        role = m.get("role", "user")
        content = (m.get("content") or "").replace("\n", " ").strip()
        if not content:
            continue
        prefix = "KH√ÅCH" if role == "user" else "BOT"
        history_text_lines.append(f"{prefix}: {content}")
    history_text = "\n".join(history_text_lines)

    prompt = f"""
B·∫°n l√† module PH√ÇN LO·∫†I √ù ƒê·ªäNH cho chatbot t∆∞ v·∫•n s·ª©c kh·ªèe & s·∫£n ph·∫©m Greenway / Welllab.

Nhi·ªám v·ª•:
- Ch·ªâ ph√¢n lo·∫°i √Ω ƒë·ªãnh, KH√îNG t·ª± t∆∞ v·∫•n s·ª©c kh·ªèe.
- D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i (n·∫øu c√≥) v√† c√¢u m·ªõi nh·∫•t c·ªßa ng∆∞·ªùi d√πng.

C√°c lo·∫°i intent h·ª£p l·ªá:
- "greeting"       : ch√†o h·ªèi, h·ªèi thƒÉm ki·ªÉu "ch√†o em", "hello", "d·∫°o n√†y sao r·ªìi"...
- "smalltalk"      : n√≥i chuy·ªán ƒë·ªùi th∆∞·ªùng, h·ªèi linh tinh, ƒë√πa vui, kh√¥ng y√™u c·∫ßu t∆∞ v·∫•n s·∫£n ph·∫©m/ch√≠nh s√°ch.
- "health_question": h·ªèi v·ªÅ tri·ªáu ch·ª©ng, t√¨nh tr·∫°ng s·ª©c kh·ªèe chung (c√≥ ho·∫∑c kh√¥ng nh·∫Øc combo/s·∫£n ph·∫©m).
- "product_question": h·ªèi v·ªÅ M·ªòT s·∫£n ph·∫©m c·ª• th·ªÉ, t√™n, c√°ch d√πng, t√°c d·ª•ng, gi√°, link...
- "combo_question" : h·ªèi g·ª£i √Ω combo / b·ªô s·∫£n ph·∫©m cho v·∫•n ƒë·ªÅ s·ª©c kh·ªèe.
- "business_policy": h·ªèi v·ªÅ ch√≠nh s√°ch, hoa h·ªìng, tuy·ªÉn d·ª•ng, thƒÉng c·∫•p, KPI, doanh s·ªë...
- "buy_payment"    : h·ªèi v·ªÅ c√°ch mua h√†ng, giao h√†ng, thanh to√°n.
- "channel_info"   : h·ªèi xin link fanpage, Zalo OA, website, k√™nh li√™n h·ªá.
- "other"          : m·ªçi tr∆∞·ªùng h·ª£p kh√°c kh√¥ng n·∫±m trong c√°c nh√≥m tr√™n.

H√£y tr·∫£ v·ªÅ JSON **duy nh·∫•t**, kh√¥ng gi·∫£i th√≠ch th√™m, d·∫°ng:

{{
  "intent": "greeting | smalltalk | health_question | product_question | combo_question | business_policy | buy_payment | channel_info | other",
  "reason": "gi·∫£i th√≠ch r·∫•t ng·∫Øn, ti·∫øng Vi·ªát"
}}

----- L·ªäCH S·ª¨ H·ªòI THO·∫†I (n·∫øu c√≥) -----
{history_text}

----- C√ÇU M·ªöI NH·∫§T C·ª¶A NG∆Ø·ªúI D√ôNG -----
"{user_message}"
"""

    raw = call_openai_responses(prompt)
    data = safe_parse_json(raw, default={"intent": "other", "reason": ""})
    intent = data.get("intent") or "other"
    data["intent"] = intent
    return data

def ai_analyze_symptom(user_message: str, history_messages: list[dict] | None = None) -> dict:
    """
    Ph√¢n t√≠ch tri·ªáu ch·ª©ng / t√¨nh hu·ªëng s·ª©c kh·ªèe ·ªü m·ª©c 'chuy√™n gia'.

    Tr·∫£ v·ªÅ JSON d·∫°ng:
    {
      "main_issue": "ti√™u ho√° / ƒë·∫°i tr√†ng / gan m·∫≠t / ...",
      "body_system": "digestive | liver | immune | cardio | other",
      "symptom_keywords": ["ƒëi ngo√†i nhi·ªÅu l·∫ßn", "ƒëau b·ª•ng", ...],
      "severity": "mild | moderate | severe",
      "recommended_groups": ["tieu_hoa", "dai_trang"],
      "suggested_tags": ["tieu_hoa", "dai_trang"]
    }
    """
    history_messages = history_messages or []
    history_text_lines = []
    for m in history_messages[-6:]:
        role = m.get("role", "user")
        content = (m.get("content") or "").replace("\n", " ").strip()
        if not content:
            continue
        prefix = "KH√ÅCH" if role == "user" else "BOT"
        history_text_lines.append(f"{prefix}: {content}")
    history_text = "\n".join(history_text_lines)

    prompt = f"""
B·∫°n l√† module PH√ÇN T√çCH TRI·ªÜU CH·ª®NG cho tr·ª£ l√Ω s·ª©c kh·ªèe Greenway/Welllab.

Nhi·ªám v·ª•:
- ƒê·ªåC v√† HI·ªÇU m√¥ t·∫£ tri·ªáu ch·ª©ng c·ªßa ng∆∞·ªùi d√πng (TVV/Leader ho·∫∑c kh√°ch).
- SUY LU·∫¨N xem v·∫•n ƒë·ªÅ ch√≠nh thu·ªôc nh√≥m n√†o, m·ª©c ƒë·ªô ra sao.
- G·ª£i √Ω c√°c nh√≥m s·∫£n ph·∫©m N√äN ∆ØU TI√äN (theo group trong d·ªØ li·ªáu: tieu_hoa, gan, than, tim_mach, mien_dich, xuong_khop,...).
- ƒê·ªÅ xu·∫•t th√™m c√°c health_tags li√™n quan (n·∫øu c√≥).

ƒê·∫ßu ra l√† JSON DUY NH·∫§T, KH√îNG gi·∫£i th√≠ch th√™m, c√≥ d·∫°ng:

{{
  "main_issue": "<m√¥ t·∫£ ng·∫Øn v·∫•n ƒë·ªÅ ch√≠nh>",
  "body_system": "digestive | liver | immune | cardio | neuro | other",
  "symptom_keywords": ["..."],
  "severity": "mild | moderate | severe",
  "recommended_groups": ["tieu_hoa", "dai_trang", "men_vi_sinh"],
  "suggested_tags": ["tieu_hoa", "dai_trang"]
}}

----- L·ªäCH S·ª¨ H·ªòI THO·∫†I G·∫¶N ƒê√ÇY (n·∫øu c√≥) -----
{history_text}

----- C√ÇU M√î T·∫¢ TRI·ªÜU CH·ª®NG / V·∫§N ƒê·ªÄ M·ªöI NH·∫§T -----
"{user_message}"
"""
    raw = call_openai_responses(prompt)
    data = safe_parse_json(
        raw,
        default={
            "main_issue": "",
            "body_system": "other",
            "symptom_keywords": [],
            "severity": "mild",
            "recommended_groups": [],
            "suggested_tags": [],
        },
    )
    # ƒê·∫£m b·∫£o c√°c field t·ªëi thi·ªÉu t·ªìn t·∫°i
    data.setdefault("main_issue", "")
    data.setdefault("body_system", "other")
    data.setdefault("symptom_keywords", [])
    data.setdefault("severity", "mild")
    data.setdefault("recommended_groups", [])
    data.setdefault("suggested_tags", [])
    return data


# =====================================================================
#   LLM PROMPTS
# =====================================================================
def llm_answer_for_combos(user_question, requested_tags, combos, covered_tags,
                          extra_instruction: str = ""):
    if not combos:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y combo ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n t∆∞ v·∫•n chi ti·∫øt h∆°n ·∫°."
        )

    combos_json = json.dumps(combos, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu combo v√† s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

D∆∞·ªõi ƒë√¢y l√† c√¢u h·ªèi v√† d·ªØ li·ªáu:

- C√¢u h·ªèi c·ªßa kh√°ch / t∆∞ v·∫•n vi√™n: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe h·ªá th·ªëng tr√≠ch xu·∫•t ƒë∆∞·ª£c: {tags_text}

D·ªØ li·ªáu c√°c combo ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{combos_json}

H∆∞·ªõng d·∫´n b·ªï sung t·ª´ h·ªá th·ªëng (c√≥ th·ªÉ ƒë·ªÉ tr·ªëng):
{extra_instruction}

Y√äU C·∫¶U TR·∫¢ L·ªúI (b·∫±ng ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu, r√µ r√†ng):

1. M·ªü ƒë·∫ßu 1‚Äì3 c√¢u: t√≥m t·∫Øt c√°c v·∫•n ƒë·ªÅ/nhu c·∫ßu ch√≠nh v√† ƒë·ªãnh h∆∞·ªõng x·ª≠ l√Ω (theo combo) cho kh√°ch.
2. V·ªõi t·ª´ng combo:
   - N√™u r√µ combo n√†y h·ªó tr·ª£ nh·ªØng v·∫•n ƒë·ªÅ n√†o trong c√°c v·∫•n ƒë·ªÅ kh√°ch ƒëang g·∫∑p.
   - Li·ªát k√™ t·ª´ng s·∫£n ph·∫©m trong combo:
     + T√™n s·∫£n ph·∫©m
     + L·ª£i √≠ch ch√≠nh / t√°c d·ª•ng h·ªó tr·ª£
     + Th·ªùi gian d√πng g·ª£i √Ω (n·∫øu c√≥ trong d·ªØ li·ªáu)
     + C√°ch d√πng t√≥m t·∫Øt (d·ª±a tr√™n dose_text/usage_text n·∫øu c√≥)
     + Gi√° (price_text)
     + Link s·∫£n ph·∫©m (product_url)
3. N·∫øu v·∫•n ƒë·ªÅ c√≥ v·∫ª n·∫∑ng/nh·∫°y c·∫£m (ung th∆∞, tim m·∫°ch n·∫∑ng, suy th·∫≠n, v.v.) h√£y khuy·∫øn ngh·ªã kh√°ch n√™n thƒÉm kh√°m v√† t√°i kh√°m ƒë·ªãnh k·ª≥.
4. Cu·ªëi c√¢u tr·∫£ l·ªùi, lu√¥n nh·∫Øc: "S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.".
5. Vi·∫øt gi·ªçng ƒëi·ªáu g·∫ßn g≈©i, l·ªãch s·ª±, h∆∞·ªõng d·∫´n nh∆∞ ƒëang n√≥i chuy·ªán v·ªõi t∆∞ v·∫•n vi√™n/kh√°ch h√†ng th·∫≠t.
"""
    return call_openai_responses(prompt)


def llm_answer_for_products(user_question, requested_tags, products,
                            extra_instruction: str = ""):
    if not products:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n r√µ h∆°n ·∫°."
        )

    products_json = json.dumps(products, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

- C√¢u h·ªèi: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe: {tags_text}

D·ªØ li·ªáu c√°c s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{products_json}

H∆∞·ªõng d·∫´n b·ªï sung t·ª´ h·ªá th·ªëng (c√≥ th·ªÉ ƒë·ªÉ tr·ªëng):
{extra_instruction}

Y√äU C·∫¶U TR·∫¢ L·ªúI:

1. M·ªü ƒë·∫ßu 1‚Äì2 c√¢u: gi·ªõi thi·ªáu ƒë√¢y l√† c√°c s·∫£n ph·∫©m h·ªó tr·ª£ ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ m√† kh√°ch ƒëang g·∫∑p.
2. V·ªõi t·ª´ng s·∫£n ph·∫©m:
   - T√™n s·∫£n ph·∫©m
   - V·∫•n ƒë·ªÅ ch√≠nh m√† s·∫£n ph·∫©m h·ªó tr·ª£ (d·ª±a tr√™n group/health_tags)
   - L·ª£i √≠ch ch√≠nh (d·ª±a tr√™n benefits_text ho·∫∑c m√¥ t·∫£)
   - C√°ch d√πng t√≥m t·∫Øt (usage_text ho·∫∑c dose_text n·∫øu c√≥)
   - Gi√° (price_text)
   - Link s·∫£n ph·∫©m (product_url)
3. Cu·ªëi c√πng nh·∫Øc: s·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.
4. Vi·∫øt ng·∫Øn g·ªçn, r√µ r√†ng, d·ªÖ d√πng cho t∆∞ v·∫•n vi√™n khi ch√°t v·ªõi kh√°ch.
"""
    return call_openai_responses(prompt)


def llm_answer_for_products(user_question, requested_tags, products):
    if not products:
        return (
            "Hi·ªán em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
            f"Anh/ch·ªã vui l√≤ng li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n r√µ h∆°n ·∫°."
        )

    products_json = json.dumps(products, ensure_ascii=False, indent=2)
    tags_text = ", ".join(requested_tags)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n cho c√¥ng ty th·ª±c ph·∫©m ch·ª©c nƒÉng Greenway/Welllab.
B·∫°n ch·ªâ ƒë∆∞·ª£c d√πng ƒë√∫ng d·ªØ li·ªáu s·∫£n ph·∫©m trong JSON b√™n d∆∞·ªõi, kh√¥ng ƒë∆∞·ª£c b·ªãa th√™m s·∫£n ph·∫©m hay c√¥ng d·ª•ng.

- C√¢u h·ªèi: "{user_question}"
- C√°c tags/v·∫•n ƒë·ªÅ s·ª©c kh·ªèe: {tags_text}

D·ªØ li·ªáu c√°c s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ch·ªçn (JSON):

{products_json}

Y√äU C·∫¶U TR·∫¢ L·ªúI:

1. M·ªü ƒë·∫ßu 1‚Äì2 c√¢u: gi·ªõi thi·ªáu ƒë√¢y l√† c√°c s·∫£n ph·∫©m h·ªó tr·ª£ ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ m√† kh√°ch ƒëang g·∫∑p.
2. V·ªõi t·ª´ng s·∫£n ph·∫©m:
   - T√™n s·∫£n ph·∫©m
   - V·∫•n ƒë·ªÅ ch√≠nh m√† s·∫£n ph·∫©m h·ªó tr·ª£ (d·ª±a tr√™n group/health_tags)
   - L·ª£i √≠ch ch√≠nh (d·ª±a tr√™n benefits_text ho·∫∑c m√¥ t·∫£)
   - C√°ch d√πng t√≥m t·∫Øt (usage_text ho·∫∑c dose_text n·∫øu c√≥)
   - Gi√° (price_text)
   - Link s·∫£n ph·∫©m (product_url)
3. Cu·ªëi c√πng nh·∫Øc: s·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh.
4. Vi·∫øt ng·∫Øn g·ªçn, r√µ r√†ng, d·ªÖ d√πng cho t∆∞ v·∫•n vi√™n khi ch√°t v·ªõi kh√°ch.
"""
    return call_openai_responses(prompt)


def llm_answer_with_history(latest_question: str, history: list) -> str:
    """
    D√πng khi c√¢u h·ªèi l√† follow-up: t·∫≠n d·ª•ng transcript h·ªôi tho·∫°i g·∫ßn ƒë√¢y.
    """
    if not history:
        # fallback cho ch·∫Øc
        return call_openai_responses(
            f"Kh√°ch h·ªèi: {latest_question}\nH√£y t∆∞ v·∫•n nh∆∞ tr·ª£ l√Ω Greenway/Welllab."
        )

    lines = []
    # L·∫•y kho·∫£ng 10 message g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh prompt qu√° d√†i
    for msg in history[-10:]:
        role = msg.get("role")
        prefix = "Kh√°ch" if role == "user" else "Tr·ª£ l√Ω"
        content = msg.get("content", "")
        lines.append(f"{prefix}: {content}")
    convo = "\n".join(lines)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n s·ª©c kh·ªèe & s·∫£n ph·∫©m cho Greenway/Welllab.

D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n h·ªôi tho·∫°i g·∫ßn ƒë√¢y gi·ªØa kh√°ch v√† tr·ª£ l√Ω (b·∫°n):

{convo}

C√¢u h·ªèi m·ªõi nh·∫•t c·ªßa kh√°ch l√†: "{latest_question}"

NHI·ªÜM V·ª§:

1. Hi·ªÉu 'combo tr√™n', 'combo ƒë√≥', 's·∫£n ph·∫©m tr√™n', 's·∫£n ph·∫©m ƒë√≥', 'g√≥i tr√™n'...
   l√† ƒëang n√≥i v·ªÅ combo/s·∫£n ph·∫©m m√† b·∫°n v·ª´a t∆∞ v·∫•n tr∆∞·ªõc ƒë√≥ trong ƒëo·∫°n h·ªôi tho·∫°i.
2. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, d·ª±a tr√™n th√¥ng tin ƒë√£ ƒë∆∞·ª£c t∆∞ v·∫•n ·ªü tr√™n
   (li·ªÅu d√πng, th·ªùi gian u·ªëng, s·ªë vi√™n m·ªói ng√†y, gi√°, c√°ch d√πng...).
3. N·∫øu trong ƒëo·∫°n h·ªôi tho·∫°i ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√≥i r√µ:
   'Trong ph·∫ßn t∆∞ v·∫•n ph√≠a tr√™n em ch∆∞a ghi r√µ ph·∫ßn n√†y, anh/ch·ªã cho em xin l·∫°i c√¢u h·ªèi ƒë·∫ßy ƒë·ªß h∆°n...'
4. Cu·ªëi c√πng v·∫´n nh·∫Øc: S·∫£n ph·∫©m kh√¥ng ph·∫£i l√† thu·ªëc v√† kh√¥ng c√≥ t√°c d·ª•ng thay th·∫ø thu·ªëc ch·ªØa b·ªánh (n·∫øu c√¢u tr·∫£ l·ªùi li√™n quan ƒë·∫øn s·∫£n ph·∫©m).

B·∫Øt ƒë·∫ßu tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, gi·ªçng t∆∞ v·∫•n vi√™n th√¢n thi·ªán, chuy√™n nghi·ªáp.
"""
    return call_openai_responses(prompt)

# =====================================================================
#   HANDLER CHO C√ÅC MODE ƒê·∫∂C BI·ªÜT
# =====================================================================
def handle_buy_and_payment_info():
    return (
        "ƒê·ªÉ mua h√†ng, anh/ch·ªã c√≥ th·ªÉ ch·ªçn m·ªôt trong c√°c c√°ch sau:\n\n"
        "1Ô∏è‚É£ ƒê·∫∑t h√†ng tr·ª±c ti·∫øp tr√™n website:\n"
        f"   ‚Ä¢ {WEBSITE_URL}\n\n"
        "2Ô∏è‚É£ Nh·∫Øn tin qua Zalo OA c·ªßa c√¥ng ty ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n v√† ch·ªët ƒë∆°n:\n"
        f"   ‚Ä¢ {ZALO_OA_URL}\n\n"
        "3Ô∏è‚É£ G·ªçi hotline ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nhanh:\n"
        f"   ‚Ä¢ {HOTLINE}\n\n"
        "V·ªÅ thanh to√°n, hi·ªán c√¥ng ty h·ªó tr·ª£:\n"
        "- Thanh to√°n khi nh·∫≠n h√†ng (COD)\n"
        "- Chuy·ªÉn kho·∫£n ng√¢n h√†ng theo h∆∞·ªõng d·∫´n t·ª´ t∆∞ v·∫•n vi√™n ho·∫∑c tr√™n website."
    )


def handle_escalate_to_hotline():
    return (
        "C√¢u h·ªèi n√†y thu·ªôc nh√≥m ch√≠nh s√°ch/k·∫ø ho·∫°ch kinh doanh chuy√™n s√¢u n√™n c·∫ßn tuy·∫øn tr√™n h·ªó tr·ª£ tr·ª±c ti·∫øp ·∫°.\n\n"
        "Anh/ch·ªã vui l√≤ng ƒë·ªÉ l·∫°i:\n"
        "- H·ªç t√™n\n"
        "- S·ªë ƒëi·ªán tho·∫°i\n"
        "- M√£ TVV (n·∫øu c√≥)\n\n"
        f"Ho·∫∑c g·ªçi th·∫≥ng hotline: {HOTLINE}\n"
        "Tuy·∫øn tr√™n s·∫Ω li√™n h·ªá v√† t∆∞ v·∫•n chi ti·∫øt cho anh/ch·ªã s·ªõm nh·∫•t c√≥ th·ªÉ."
    )


def handle_channel_navigation():
    return (
        "Anh/ch·ªã c√≥ th·ªÉ theo d√µi th√¥ng tin, ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i v√† ki·∫øn th·ª©c s·ª©c kh·ªèe t·∫°i c√°c k√™nh sau:\n\n"
        f"üìò Fanpage: {FANPAGE_URL}\n"
        f"üí¨ Zalo OA: {ZALO_OA_URL}\n"
        f"üåê Website: {WEBSITE_URL}\n\n"
        "N·∫øu c·∫ßn h·ªó tr·ª£ g·∫•p, anh/ch·ªã g·ªçi tr·ª±c ti·∫øp hotline gi√∫p em nh√©."
    )

# =====================================================================
#   MODE DETECTION
# =====================================================================
def detect_mode(user_message: str) -> str:
    """ƒêo√°n xem user ƒëang h·ªèi v·ªÅ combo / s·∫£n ph·∫©m / mua h√†ng / k√™nh / kinh doanh."""
    text_norm = strip_accents(user_message)

    # H·ªèi kinh doanh, ch√≠nh s√°ch, hoa h·ªìng
    business_keywords = [
        "chinh sach",
        "hoa hong",
        "tuyen dung",
        "len cap",
        "leader",
        "doanh so",
        "muc tieu thang",
    ]
    if any(k in text_norm for k in business_keywords):
        return "business"

    # H·ªèi mua h√†ng / thanh to√°n
    buy_keywords = [
        "mua",
        "dat hang",
        "thanh toan",
        "ship",
        "giao hang",
        "dat mua",
    ]
    if any(k in text_norm for k in buy_keywords):
        return "buy"

    # H·ªèi k√™nh, fanpage, zalo
    channel_keywords = [
        "fanpage",
        "zalo",
        "kenh",
        "website",
        "trang web",
    ]
    if any(k in text_norm for k in channel_keywords):
        return "channel"

    # Nh·∫Øc ƒë·∫øn combo / s·∫£n ph·∫©m
    if "combo" in text_norm:
        return "combo"
    if "san pham" in text_norm or "s·∫£n ph·∫©m" in user_message.lower():
        return "product"

    return "auto"

# =====================================================================
#   LOG CONVERSATION ‚Üí GOOGLE SHEETS
# =====================================================================
def log_conversation(payload: dict):
    if not LOG_WEBHOOK_URL:
        return
    try:
        requests.post(LOG_WEBHOOK_URL, json=payload, timeout=2)
    except Exception as e:
        print("[WARN] Log error:", e)

# =====================================================================
#   CORE CHAT LOGIC
# =====================================================================
def handle_chat(
    user_message: str,
    mode: str | None = None,
    session_id: str | None = None,
    return_meta: bool = False,
    history: list | None = None,
):
    text = (user_message or "").strip()
    history = history or []

    if not text:
        reply = "Em ch∆∞a nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi c·ªßa anh/ch·ªã."
        if return_meta:
            meta = {
                "intent": "",
                "mode_detected": "",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
            }
            return reply, meta
        return reply

    # D√πng history ƒë∆∞·ª£c truy·ªÅn t·ª´ /openai-chat cho AI ph√¢n lo·∫°i intent
    history_messages = history

    # 1) G·ªçi AI ph√¢n lo·∫°i √Ω ƒë·ªãnh
    intent_info = ai_classify_intent(text, history_messages)
    intent = intent_info.get("intent", "other")
    print("[INTENT]", intent, "|", intent_info.get("reason", ""))

    # 2) PH√ÇN T√çCH TRI·ªÜU CH·ª®NG ·ªû T·∫¶NG CHUY√äN GIA
    analysis = {}
    ai_tags = []
    ai_groups = []
    expert_extra_note = ""

    if intent in ("health_question", "combo_question", "product_question", "other"):
        analysis = ai_analyze_symptom(text, history_messages)
        ai_tags = analysis.get("suggested_tags") or []
        ai_groups = analysis.get("recommended_groups") or []

        expert_extra_note = (
            "T√ìM T·∫ÆT PH√ÇN T√çCH CHUY√äN GIA (kh√¥ng c·∫ßn in nguy√™n vƒÉn, ch·ªâ d√πng ƒë·ªÉ ƒë·ªãnh h∆∞·ªõng t∆∞ v·∫•n):\n"
            f"- V·∫•n ƒë·ªÅ ch√≠nh: {analysis.get('main_issue', '')}\n"
            f"- H·ªá c∆° quan: {analysis.get('body_system', '')}\n"
            f"- M·ª©c ƒë·ªô g·ª£i √Ω: {analysis.get('severity', '')}\n"
            "H√£y gi·∫£i th√≠ch cho ng∆∞·ªùi d√πng theo h∆∞·ªõng chuy√™n gia s·ª©c kh·ªèe, d·ªÖ hi·ªÉu, "
            "tr√¨nh b√†y r√µ: v·∫•n ƒë·ªÅ ch√≠nh l√† g√¨, h∆∞·ªõng h·ªó tr·ª£ ∆∞u ti√™n ra sao, "
            "sau ƒë√≥ m·ªõi ƒëi v√†o combo/s·∫£n ph·∫©m c·ª• th·ªÉ.\n"
        )
    else:
        analysis = {
            "main_issue": "",
            "body_system": "other",
            "symptom_keywords": [],
            "severity": "mild",
            "recommended_groups": [],
            "suggested_tags": [],
        }

    # ================== ROUTING THEO INTENT T·ª∞ NHI√äN ==================
    # 1. Ch√†o h·ªèi
    if intent == "greeting":
        reply = (
            "D·∫° em ch√†o anh/ch·ªã ·∫° üòä\n"
            "Anh/ch·ªã c·ª© chia s·∫ª gi√∫p em v·∫•n ƒë·ªÅ s·ª©c kh·ªèe ho·∫∑c nhu c·∫ßu v·ªÅ s·∫£n ph·∫©m, "
            "em s·∫Ω g·ª£i √Ω combo/s·∫£n ph·∫©m ph√π h·ª£p ·∫°."
        )
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "greeting",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return reply, meta
        return reply

    # 2. N√≥i chuy·ªán ƒë·ªùi th∆∞·ªùng / h·ªèi vu v∆°
    if intent == "smalltalk":
        smalltalk_reply = call_openai_responses(
            f"""
    B·∫°n l√† tr·ª£ l√Ω s·ª©c kh·ªèe Greenway/Welllab.
    Ng∆∞·ªùi d√πng ƒëang CH·ªà N√ìI CHUY·ªÜN ƒê·ªúI TH∆Ø·ªúNG, kh√¥ng y√™u c·∫ßu t∆∞ v·∫•n c·ª• th·ªÉ.

    H√£y tr·∫£ l·ªùi th√¢n thi·ªán, ng·∫Øn g·ªçn (2-4 c√¢u), c√≥ th·ªÉ ƒë√πa nh·∫π, 
    sau ƒë√≥ kh√©o l√©o g·ª£i √Ω r·∫±ng n·∫øu h·ªç c·∫ßn t∆∞ v·∫•n v·ªÅ s·ª©c kh·ªèe / s·∫£n ph·∫©m / combo th√¨ b·∫°n lu√¥n s·∫µn s√†ng.

    C√¢u c·ªßa ng∆∞·ªùi d√πng: "{text}"
    """
        )
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "smalltalk",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return smalltalk_reply, meta
        return smalltalk_reply

    # 3. Ch√≠nh s√°ch / kinh doanh
    if intent == "business_policy":
        reply = handle_escalate_to_hotline()
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "business",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return reply, meta
        return reply

    # 4. C√°ch mua h√†ng / thanh to√°n
    if intent == "buy_payment":
        reply = handle_buy_and_payment_info()
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "buy",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return reply, meta
        return reply

    # 5. H·ªèi k√™nh li√™n h·ªá
    if intent == "channel_info":
        reply = handle_channel_navigation()
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "channel",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return reply, meta
        return reply

    # 6. Tuning mode cho c√°c c√¢u s·ª©c kh·ªèe (∆∞u ti√™n intent AI)
    if intent == "combo_question":
        mode = "combo"
    elif intent == "product_question":
        mode = "product"
    elif intent == "health_question":
        if not mode:
            mode = "auto"

    # 7. Follow-up ki·ªÉu "combo tr√™n u·ªëng bao l√¢u" ‚Üí d√πng l·ªãch s·ª≠
    if history and looks_like_followup(text):
        reply = llm_answer_with_history(text, history)
        if return_meta:
            meta = {
                "intent": intent,
                "mode_detected": "followup",
                "health_tags": [],
                "selected_combos": [],
                "selected_products": [],
                "ai_main_issue": analysis.get("main_issue", ""),
                "ai_body_system": analysis.get("body_system", ""),
                "ai_severity": analysis.get("severity", ""),
                "ai_groups": ai_groups,
            }
            return reply, meta
        return reply

    # 8. Mode + tags + extra_instruction cho LLM
    detected_mode = detect_mode(text) if not mode else mode.lower().strip()
    mode = detected_mode

    requested_tags = extract_tags_from_text(text)
    requested_tags = list(set((requested_tags or []) + (ai_tags or [])))
    extra_instruction = expert_extra_note  # ri√™ng t·∫ßng chuy√™n gia A1

    meta = {
        "intent": intent,
        "mode_detected": mode,
        "health_tags": requested_tags,
        "selected_combos": [],
        "selected_products": [],
        "ai_main_issue": analysis.get("main_issue", ""),
        "ai_body_system": analysis.get("body_system", ""),
        "ai_severity": analysis.get("severity", ""),
        "ai_groups": ai_groups,
    }

    print("[DEBUG] handle_chat mode =", mode, "| text =", text)
    print("[DEBUG] requested_tags =", requested_tags, "| ai_groups =", ai_groups)

    # 9. C√°c mode ƒë∆°n gi·∫£n
    if mode == "buy":
        reply = handle_buy_and_payment_info()
        if return_meta:
            return reply, meta
        return reply

    if mode == "channel":
        reply = handle_channel_navigation()
        if return_meta:
            return reply, meta
        return reply

    if mode == "business":
        reply = handle_escalate_to_hotline()
        if return_meta:
            return reply, meta
        return reply

    # 10. C√°c mode v·ªÅ s·ª©c kh·ªèe: combo / product / auto
    want_combo = "combo" in strip_accents(text) or mode == "combo"
    want_product = (
        "san pham" in strip_accents(text)
        or "s·∫£n ph·∫©m" in text.lower()
        or mode == "product"
    )

    # 10.1. ∆Øu ti√™n combo n·∫øu ng∆∞·ªùi d√πng h·ªèi combo
    if want_combo and not want_product:
        combos, covered_tags = select_combos_for_tags(requested_tags, text)
        meta["selected_combos"] = [c.get("id") for c in combos]

        if combos:
            reply = llm_answer_for_combos(text, requested_tags, combos, covered_tags, extra_instruction)
            if return_meta:
                return reply, meta
            return reply

        # Kh√¥ng c√≥ combo ‚Üí fallback sang s·∫£n ph·∫©m (tags + group chuy√™n gia)
        products = search_products_by_tags(requested_tags)
        if (not products) and ai_groups:
            products = search_products_by_groups(ai_groups)
        meta["selected_products"] = [p.get("id") for p in products]

        if products:
            reply = llm_answer_for_products(text, requested_tags, products, extra_instruction)
            if return_meta:
                return reply, meta
            return reply

    # 10.2. Ng∆∞·ªùi d√πng h·ªèi s·∫£n ph·∫©m
    if want_product and not want_combo:
        products = search_products_by_tags(requested_tags)
        if (not products) and ai_groups:
            products = search_products_by_groups(ai_groups)
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(text, requested_tags, products, extra_instruction)
        if return_meta:
            return reply, meta
        return reply

    # 10.3. AUTO: ∆∞u ti√™n combo, n·∫øu kh√¥ng c√≥ th√¨ show s·∫£n ph·∫©m
    combos, covered_tags = select_combos_for_tags(requested_tags, text)
    if combos:
        meta["selected_combos"] = [c.get("id") for c in combos]
        reply = llm_answer_for_combos(text, requested_tags, combos, covered_tags, extra_instruction)
        if return_meta:
            return reply, meta
        return reply

    products = search_products_by_tags(requested_tags)
    if (not products) and ai_groups:
        products = search_products_by_groups(ai_groups)
    if products:
        meta["selected_products"] = [p.get("id") for p in products]
        reply = llm_answer_for_products(text, requested_tags, products, extra_instruction)
        if return_meta:
            return reply, meta
        return reply

    # 11. Kh√¥ng match ƒë∆∞·ª£c g√¨
    reply = (
        "Hi·ªán em ch∆∞a t√¨m th·∫•y combo hay s·∫£n ph·∫©m n√†o ph√π h·ª£p trong d·ªØ li·ªáu cho tr∆∞·ªùng h·ª£p n√†y. "
        f"Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n t√¨nh tr·∫°ng s·ª©c kh·ªèe, ho·∫∑c li√™n h·ªá hotline {HOTLINE} ƒë·ªÉ tuy·∫øn tr√™n h·ªó tr·ª£ k·ªπ h∆°n ·∫°."
    )
    if return_meta:
        return reply, meta
    return reply

# =====================================================================
#   API /openai-chat ‚Äì LOG DB + NH·ªö C√ÇU C≈® + NG·ªÆ C·∫¢NH
# =====================================================================
@app.route("/openai-chat", methods=["POST"])
def openai_chat():
    start_time = time.time()
    try:
        body = request.get_json(force=True) or {}

        user_message = (body.get("message") or "").strip()
        mode = (
            (body.get("mode") or "").strip().lower()
            if isinstance(body, dict)
            else ""
        )
        session_id = body.get("session_id") or ""
        channel = body.get("channel") or "web"
        user_id = body.get("user_id") or ""

        # N·∫øu client kh√¥ng g·ª≠i session_id, t·ª± sinh t·∫°m (√≠t nh·∫•t cho web demo)
        if not session_id:
            session_id = f"web-{request.remote_addr}-{int(time.time())}"

        used_history_message = ""
        message_for_ai = user_message

        # 1) Tr∆∞·ªõc khi l∆∞u DB, ki·ªÉm tra xem c√≥ ph·∫£i 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n' kh√¥ng
        if looks_like_repeat_request(user_message) and session_id:
            last_q = get_last_user_message(session_id)
            if last_q:
                used_history_message = last_q
                message_for_ai = last_q
                print(
                    "[DEBUG] Repeat request detected. Using last user question:",
                    last_q,
                )

        # 2) L∆∞u message g·ªëc c·ªßa user v√†o DB
        try:
            save_message(session_id, "user", user_message)
        except Exception as e:
            print("[DB ERROR] Cannot save user message:", e)

        # 3) L·∫•y history sau khi ƒë√£ l∆∞u, ƒë·ªÉ follow-up hi·ªÉu ƒë∆∞·ª£c c·∫£ c√¢u v·ª´a h·ªèi
        history = []
        try:
            history = get_recent_history(session_id, limit=10)
        except Exception as e:
            print("[DB ERROR] Cannot get history:", e)

        # 4) X·ª≠ l√Ω chat ‚Äì d√πng message_for_ai (ƒë√£ x·ª≠ l√Ω 'tr·∫£ l·ªùi l·∫°i c√¢u h·ªèi tr√™n')
        reply_text, meta = handle_chat(
            message_for_ai,
            mode or None,
            session_id=session_id,
            return_meta=True,
            history=history,
        )

        # 5) L∆∞u bot reply v√†o DB
        try:
            save_message(session_id, "assistant", reply_text)
        except Exception as e:
            print("[DB ERROR] Cannot save bot reply:", e)

        latency_ms = int((time.time() - start_time) * 1000)

        # 6) G·ª≠i log sang Google Sheets (webhook Apps Script)
        log_payload = {
            "timestamp": datetime.utcnow().isoformat(),
            "channel": channel,
            "session_id": session_id,
            "user_id": user_id,
            "user_message": user_message,
            "message_for_ai": message_for_ai,
            "used_history_message": used_history_message,
            "bot_reply": reply_text,
            "intent": meta.get("intent", ""),
            "mode_detected": meta.get("mode_detected"),
            "health_tags": meta.get("health_tags", []),
            "selected_combos": meta.get("selected_combos", []),
            "selected_products": meta.get("selected_products", []),
            "ai_main_issue": meta.get("ai_main_issue", ""),
            "ai_body_system": meta.get("ai_body_system", ""),
            "ai_severity": meta.get("ai_severity", ""),
            "ai_groups": meta.get("ai_groups", []),
            "latency_ms": latency_ms,
        }

        log_conversation(log_payload)

        return jsonify({"reply": reply_text})

    except Exception as e:
        print("‚ùå ERROR /openai-chat:", e)
        return jsonify(
            {
                "reply": "Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng ƒëang g·∫∑p l·ªói. Anh/ch·ªã vui l√≤ng th·ª≠ l·∫°i sau nh√©."
            }
        ), 500

# =====================================================================
#   AUTH ‚Äì ƒêƒÇNG K√ù TVV T·ª™ TRANG INDEX
# =====================================================================
@app.route("/auth/register", methods=["POST"])
def auth_register():
    """
    Trang index.html g·ª≠i th√¥ng tin:
    {
      "full_name": "...",
      "phone": "...",
      "email": "...",
      "company_name": "...",
      "tvv_code": "..."   # c√≥ th·ªÉ b·ªè tr·ªëng, server t·ª± d√πng phone l√†m m√£
    }
    Tr·∫£ v·ªÅ: { "tvv_code": "...", "message": "..." }
    """
    try:
        body = request.get_json(force=True) or {}
        full_name = (body.get("full_name") or "").strip()
        phone = (body.get("phone") or "").strip()
        email = (body.get("email") or "").strip()
        company_name = (body.get("company_name") or "").strip()
        tvv_code = (body.get("tvv_code") or "").strip()

        if not full_name or not phone:
            return jsonify(
                {"error": "H·ªç t√™n v√† s·ªë ƒëi·ªán tho·∫°i l√† b·∫Øt bu·ªôc."}
            ), 400

        # N·∫øu kh√¥ng nh·∫≠p m√£ TVV, d√πng lu√¥n s·ªë ƒëi·ªán tho·∫°i l√†m m√£
        if not tvv_code:
            tvv_code = phone

        upsert_tvv_user(
            tvv_code=tvv_code,
            full_name=full_name,
            phone=phone,
            email=email,
            company_name=company_name,
        )

        # Log sang Google Sheets n·∫øu √¥ng ch·ªß mu·ªën theo d√µi ƒëƒÉng k√Ω
        try:
            log_conversation(
                {
                    "timestamp": datetime.utcnow().isoformat(),
                    "channel": "web_register",
                    "session_id": "",
                    "user_id": tvv_code,
                    "user_message": f"REGISTER: {full_name} / {phone} / {email}",
                    "message_for_ai": "",
                    "used_history_message": "",
                    "bot_reply": "",
                    "intent": "register_tvv",
                    "mode_detected": "",
                    "health_tags": [],
                    "selected_combos": [],
                    "selected_products": [],
                    "latency_ms": 0,
                }
            )
        except Exception as e:
            print("[WARN] log register error:", e)

        return jsonify(
            {
                "tvv_code": tvv_code,
                "message": "ƒêƒÉng k√Ω th√†nh c√¥ng. Leader s·∫Ω k√≠ch ho·∫°t g√≥i s·ª≠ d·ª•ng cho t√†i kho·∫£n n√†y.",
            }
        )

    except Exception as e:
        print("‚ùå ERROR /auth/register:", e)
        return jsonify({"error": "L·ªói h·ªá th·ªëng khi ƒëƒÉng k√Ω TVV."}), 500
# =====================================================================
#   ADMIN ‚Äì XEM DANH S√ÅCH TVV (H·ªí S∆† T∆Ø V·∫§N VI√äN)
# =====================================================================
def require_admin_secret():
    if not ADMIN_SECRET:
        return False, "ADMIN_SECRET ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh tr√™n server."
    header_secret = request.headers.get("X-Admin-Secret") or ""
    if header_secret != ADMIN_SECRET:
        return False, "Sai ADMIN_SECRET."
    return True, ""


@app.route("/admin/users", methods=["GET"])
def admin_list_users():
    ok, msg = require_admin_secret()
    if not ok:
        status = 500 if "ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh" in msg else 401
        return jsonify({"error": msg}), status

    q = (request.args.get("q") or "").strip()
    try:
        limit = int(request.args.get("limit") or "200")
    except ValueError:
        limit = 200

    try:
        items = list_tvv_users(q=q, limit=limit)
        return jsonify({"items": items})
    except Exception as e:
        print("‚ùå ERROR /admin/users:", e)
        return jsonify({"error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch TVV."}), 500


@app.route("/debug-db", methods=["GET"])
def debug_db():
    try:
        conn = get_db_conn()
        with conn.cursor() as cur:
            cur.execute("SELECT NOW()")
            now = cur.fetchone()[0]
        conn.close()
        return f"DB OK, time = {now}", 200
    except Exception as e:
        return f"DB ERROR: {e}", 500

# =====================================================================
#   HEALTHCHECK
# =====================================================================
@app.route("/", methods=["GET"])
def home():
    return "üî• Greenway / Welllab Chatbot Gateway ƒëang ch·∫°y ngon l√†nh!", 200


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
